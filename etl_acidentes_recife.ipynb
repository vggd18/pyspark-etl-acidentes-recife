{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyMkb0s83PfE25yo+odRmK5T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vggd18/pyspark-etl-acidentes-recife/blob/main/etl_acidentes_recife.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Projeto de Data Lakehouse: Acidentes de Trânsito do Recife\n",
        "\n",
        "**Objetivo:** Construir um pipeline de dados completo (ETL) utilizando PySpark e Delta Lake para processar dados abertos de acidentes de trânsito da cidade do Recife. O projeto segue a arquitetura Medalhão (Bronze, Silver, Gold) para criar um Data Lakehouse robusto, otimizado e pronto para análises.\n",
        "\n",
        "**Ferramentas:** PySpark, Delta Lake, Python\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "CKsrA3LRd2Sy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Configuração do Ambiente (Environment Setup)\n",
        "\n",
        "Nesta seção, preparamos nosso ambiente de desenvolvimento no Google Colab, instalando as bibliotecas necessárias e configurando a sessão Spark com suporte ao Delta Lake."
      ],
      "metadata": {
        "id": "YcM2dhRsd438"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Download dos Dados de Origem (Source Data)\n",
        "\n",
        "A primeira etapa do pipeline é a ingestão dos dados brutos. Aqui, fazemos o download dos arquivos CSV anuais (2019-2024) diretamente do [Portal de Dados Abertos da Prefeitura do Recife](http://dados.recife.pe.gov.br/dataset/acidentes-de-transito-com-e-sem-vitimas)."
      ],
      "metadata": {
        "id": "8f4QrjlUhaUV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jr0OGJZGc4z5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61cc493e-17a1-4bf4-d19b-5a911ae41bea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive acidentes_2019.csv downloaded successfully.\n",
            "Archive acidentes_2020.csv downloaded successfully.\n",
            "Archive acidentes_2021.csv downloaded successfully.\n",
            "Archive acidentes_2022.csv downloaded successfully.\n",
            "Archive acidentes_2023.csv downloaded successfully.\n",
            "Archive acidentes_2024.csv downloaded successfully.\n",
            "All files downloaded successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "urls = {\n",
        "  \"2019\": \"http://dados.recife.pe.gov.br/dataset/44087d2d-73b5-4ab3-9bd8-78da7436eed1/resource/3531bafe-d47d-415e-b154-a881081ac76c/download/acidentes-2019.csv\",\n",
        "  \"2020\": \"http://dados.recife.pe.gov.br/dataset/44087d2d-73b5-4ab3-9bd8-78da7436eed1/resource/fc1c8460-0406-4fff-b51a-e79205d1f1ab/download/acidentes_2020-novo.csv\",\n",
        "  \"2021\": \"http://dados.recife.pe.gov.br/dataset/44087d2d-73b5-4ab3-9bd8-78da7436eed1/resource/2caa8f41-ccd9-4ea5-906d-f66017d6e107/download/acidentes2021.csv\",\n",
        "  \"2022\": \"http://dados.recife.pe.gov.br/dataset/44087d2d-73b5-4ab3-9bd8-78da7436eed1/resource/971e0228-fa9c-4a42-b360-c842b29d2f56/download/acidentes2022.csv\",\n",
        "  \"2023\": \"http://dados.recife.pe.gov.br/dataset/44087d2d-73b5-4ab3-9bd8-78da7436eed1/resource/d26b864b-0f7b-403e-b142-fd9989acaaf5/download/acidentes2023.csv\",\n",
        "  \"2024\": \"http://dados.recife.pe.gov.br/dataset/44087d2d-73b5-4ab3-9bd8-78da7436eed1/resource/29afbf42-a36c-475c-8b75-761e17e67679/download/acidentes2024.csv\"\n",
        "}\n",
        "\n",
        "output_dir = 'data'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for year, url in urls.items():\n",
        "  file_name = f\"acidentes_{year}.csv\"\n",
        "  file_path =  os.path.join(output_dir, file_name)\n",
        "\n",
        "  response = requests.get(url)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    with open(file_path, 'wb') as file:\n",
        "      file.write(response.content)\n",
        "    print(f\"Archive {file_name} downloaded successfully.\")\n",
        "  else:\n",
        "    print(f\"Failed to download {file_name}. Status code: {response.status_code}\")\n",
        "\n",
        "print(\"All files downloaded successfully.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Inicialização da Sessão Spark (Spark Session)\n",
        "\n",
        "Configuramos uma sessão Spark habilitada para o Delta Lake. Utilizamos a função `configure_spark_with_delta_pip` que garante a correta configuração das dependências Java (JARs), resolvendo os desafios de compatibilidade do ambiente."
      ],
      "metadata": {
        "id": "99x-01frg66S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==3.5.1 delta-spark==3.2.0 -q"
      ],
      "metadata": {
        "id": "He-KhOAogXfG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from delta import *\n",
        "\n",
        "builder = (\n",
        "  SparkSession.builder.appName(\"EtlAcidentesRecife\")\n",
        "  .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
        "  .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
        ")\n",
        "\n",
        "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
        "\n",
        "print(\"SparkSession and Delta Lake configured successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrV8TGwvhCBJ",
        "outputId": "f74e1f12-2b0d-445f-d971-a00dde708dc2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SparkSession and Delta Lake configured successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Camada Bronze: Ingestão e Armazenamento dos Dados Brutos\n",
        "\n",
        "O objetivo da Camada Bronze é criar uma cópia fiel, histórica e imutável dos dados de origem. Nesta etapa, lemos todos os arquivos CSV, lidamos com as inconsistências de schema e salvamos os dados em uma única tabela Delta particionada."
      ],
      "metadata": {
        "id": "6r1Ge_RYjEuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. Análise de Consistência do Schema (Schema Drift Analysis)\n",
        "\n",
        "Antes de carregar todos os arquivos, é uma boa prática verificar se eles possuem a mesma estrutura. Nosso script de análise revelou um **Schema Drift** significativo: os nomes e o número de colunas mudam ao longo dos anos. Esta descoberta é crucial e justifica a necessidade de um schema unificado manual."
      ],
      "metadata": {
        "id": "oFRfPIM-jIok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_acidentes = spark.read \\\n",
        "  .option(\"header\", \"true\") \\\n",
        "  .option(\"inferSchema\", \"true\") \\\n",
        "  .option(\"delimiter\", \";\") \\\n",
        "  .csv('data/acidentes_2019.csv')"
      ],
      "metadata": {
        "id": "FoNzGbl1jKL3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_acidentes.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpX2ifrwj54a",
        "outputId": "f7c8b277-271b-45a1-f8d6-6c9a3355c748"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- DATA: date (nullable = true)\n",
            " |-- hora: string (nullable = true)\n",
            " |-- natureza_acidente: string (nullable = true)\n",
            " |-- situacao: string (nullable = true)\n",
            " |-- bairro: string (nullable = true)\n",
            " |-- endereco: string (nullable = true)\n",
            " |-- numero: string (nullable = true)\n",
            " |-- detalhe_endereco_acidente: string (nullable = true)\n",
            " |-- complemento: string (nullable = true)\n",
            " |-- endereco_cruzamento: string (nullable = true)\n",
            " |-- numero_cruzamento: string (nullable = true)\n",
            " |-- referencia_cruzamento: string (nullable = true)\n",
            " |-- bairro_cruzamento: string (nullable = true)\n",
            " |-- num_semaforo: integer (nullable = true)\n",
            " |-- sentido_via: string (nullable = true)\n",
            " |-- tipo: string (nullable = true)\n",
            " |-- descricao: string (nullable = true)\n",
            " |-- auto: integer (nullable = true)\n",
            " |-- moto: integer (nullable = true)\n",
            " |-- ciclom: integer (nullable = true)\n",
            " |-- ciclista: integer (nullable = true)\n",
            " |-- pedestre: integer (nullable = true)\n",
            " |-- onibus: integer (nullable = true)\n",
            " |-- caminhao: integer (nullable = true)\n",
            " |-- viatura: integer (nullable = true)\n",
            " |-- outros: integer (nullable = true)\n",
            " |-- vitimas: integer (nullable = true)\n",
            " |-- vitimasfatais: integer (nullable = true)\n",
            " |-- acidente_verificado: string (nullable = true)\n",
            " |-- tempo_clima: string (nullable = true)\n",
            " |-- situacao_semaforo: string (nullable = true)\n",
            " |-- sinalizacao: string (nullable = true)\n",
            " |-- condicao_via: string (nullable = true)\n",
            " |-- conservacao_via: string (nullable = true)\n",
            " |-- ponto_controle: string (nullable = true)\n",
            " |-- situacao_placa: string (nullable = true)\n",
            " |-- velocidade_max_via: string (nullable = true)\n",
            " |-- mao_direcao: string (nullable = true)\n",
            " |-- divisao_via1: string (nullable = true)\n",
            " |-- divisao_via2: string (nullable = true)\n",
            " |-- divisao_via3: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_acidentes.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVXYPaJckD_6",
        "outputId": "abb46c63-9ae9-4d1b-b0f5-c5188a0fc4e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+-----------------+----------+-----------+-------------------------------+------+---------------------------+-----------------------------------------------------------+-------------------------------+-----------------+-----------------------------------------------------------+-----------------+------------+-----------+------------------------+-----------------------------------------------------------------------------------+----+----+------+--------+--------+------+--------+-------+------+-------+-------------+-------------------+-----------+-----------------+---------------+------------+---------------+-----------------+--------------+------------------+-----------+----------------+------------+------------+\n",
            "|DATA      |hora    |natureza_acidente|situacao  |bairro     |endereco                       |numero|detalhe_endereco_acidente  |complemento                                                |endereco_cruzamento            |numero_cruzamento|referencia_cruzamento                                      |bairro_cruzamento|num_semaforo|sentido_via|tipo                    |descricao                                                                          |auto|moto|ciclom|ciclista|pedestre|onibus|caminhao|viatura|outros|vitimas|vitimasfatais|acidente_verificado|tempo_clima|situacao_semaforo|sinalizacao    |condicao_via|conservacao_via|ponto_controle   |situacao_placa|velocidade_max_via|mao_direcao|divisao_via1    |divisao_via2|divisao_via3|\n",
            "+----------+--------+-----------------+----------+-----------+-------------------------------+------+---------------------------+-----------------------------------------------------------+-------------------------------+-----------------+-----------------------------------------------------------+-----------------+------------+-----------+------------------------+-----------------------------------------------------------------------------------+----+----+------+--------+--------+------+--------+-------+------+-------+-------------+-------------------+-----------+-----------------+---------------+------------+---------------+-----------------+--------------+------------------+-----------+----------------+------------+------------+\n",
            "|2019-01-01|00:41:00|SEM VÍTIMA       |FINALIZADA|IPSEP      |AV RECIFE                      |NULL  |NULL                       |LADO OPOSTO AO Nº 3257                                     |AV RECIFE                      |NULL             |LADO OPOSTO AO Nº 3257                                     |IPSEP            |NULL        |SUBURBIO   |COLISÃO TRASEIRA        |ART.181, OBSTRUÇÃO DE ENTRADA E SAÍDA DE GARAGEM DO CONDOMINIO                     |2   |NULL|NULL  |NULL    |NULL    |NULL  |NULL    |NULL   |NULL  |0      |NULL         |Longo da via       |Bom        |Não existe       |Perfeito estado|Seca        |Perfeito estado|Não existe       |Não há placas |60 km/h           |Única      |Faixa seccionada|NULL        |NULL        |\n",
            "|2019-01-01|01:37:00|SEM VÍTIMA       |FINALIZADA|BOA VIAGEM |RUA PADRE BERNADINO PESSOA     |NULL  |RUA MINISTRO NELSON HUNGRIA|NULL                                                       |RUA PADRE BERNADINO PESSOA     |NULL             |NULL                                                       |BOA VIAGEM       |NULL        |NULL       |ABALROAMENTO TRANSVERSAL|COLISÃO ENTRE DOIS AUTOS S/V                                                       |2   |NULL|NULL  |NULL    |NULL    |NULL  |NULL    |NULL   |NULL  |0      |NULL         |Cruzamento         |Bom        |Não existe       |Perfeito estado|Seca        |Perfeito estado|Faixa de pedestre|Não há placas |NULL              |Única      |Não existe      |NULL        |NULL        |\n",
            "|2019-01-01|14:20:00|SEM VÍTIMA       |CANCELADA |BOA VIAGEM |AV ENGENHEIRO DOMINGOS FERREIRA|NULL  |RUA DOM JOSE LOPES         |EM FRENTE A DELEGACIA DE BOA VIAGEM, LADO ESQUERDO DA PISTA|AV ENGENHEIRO DOMINGOS FERREIRA|NULL             |EM FRENTE A DELEGACIA DE BOA VIAGEM, LADO ESQUERDO DA PISTA|BOA VIAGEM       |NULL        |NULL       |COLISÃO                 |COLISÃO ENTRE DOIS AUTOS S/V                                                       |2   |NULL|NULL  |NULL    |NULL    |NULL  |NULL    |NULL   |NULL  |0      |NULL         |NULL               |NULL       |NULL             |NULL           |NULL        |NULL           |NULL             |NULL          |NULL              |NULL       |NULL            |NULL        |NULL        |\n",
            "|2019-01-01|02:53:00|SEM VÍTIMA       |CANCELADA |IMBIRIBEIRA|AV GENERAL MAC ARTHUR          |100   |RUA JACY                   |EM FRENTE A ART LED ILUMINAÇÃO                             |AV GENERAL MAC ARTHUR          |100              |EM FRENTE A ART LED ILUMINAÇÃO                             |IMBIRIBEIRA      |NULL        |NULL       |COLISÃO                 |COLISÃO ENTRE DOIS AUTOS S/V                                                       |2   |NULL|NULL  |NULL    |NULL    |NULL  |NULL    |NULL   |NULL  |0      |NULL         |NULL               |NULL       |NULL             |NULL           |NULL        |NULL           |NULL             |NULL          |NULL              |NULL       |NULL            |NULL        |NULL        |\n",
            "|2019-01-01|08:17:00|COM VÍTIMA       |FINALIZADA|JAQUEIRA   |RUA TITO ROSAS                 |63    |NULL                       |ED. JARDINS DA JAQUEIRA                                    |RUA TITO ROSAS                 |63               |ED. JARDINS DA JAQUEIRA                                    |JAQUEIRA         |NULL        |SUBURBIO   |COLISÃO COM CICLISTA    |COLISÃO ENVOLVENDO ÔNIBUS E BICICLETA COM VÍTIMA. EQUIPE DEPAROU-SE COM O ACIDENTE.|NULL|NULL|NULL  |1       |NULL    |1     |NULL    |NULL   |NULL  |1      |NULL         |Longo da via       |Bom        |Não existe       |Perfeito estado|Seca        |Perfeito estado|Não existe       |Não há placas |40 km/h           |Única      |Faixa seccionada|NULL        |NULL        |\n",
            "+----------+--------+-----------------+----------+-----------+-------------------------------+------+---------------------------+-----------------------------------------------------------+-------------------------------+-----------------+-----------------------------------------------------------+-----------------+------------+-----------+------------------------+-----------------------------------------------------------------------------------+----+----+------+--------+--------+------+--------+-------+------+-------+-------------+-------------------+-----------+-----------------+---------------+------------+---------------+-----------------+--------------+------------------+-----------+----------------+------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_acidentes.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b2K_6GVBQSo",
        "outputId": "4948a92b-43e5-4ed4-dd71-4b736ed0c003"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+-----------------+---------+---------+-------------------+------------------+-------------------------+--------------------+-------------------+------------------+---------------------+-----------------+------------------+-----------------+--------------------+------------------+------------------+------------------+------+-------------------+-------------------+-------------------+-------------------+------------------+-------------------+-------------------+-------------+-------------------+-----------+-----------------+---------------+------------+---------------+--------------+--------------+------------------+-----------+------------+------------+------------+\n",
            "|summary|    hora|natureza_acidente| situacao|   bairro|           endereco|            numero|detalhe_endereco_acidente|         complemento|endereco_cruzamento| numero_cruzamento|referencia_cruzamento|bairro_cruzamento|      num_semaforo|      sentido_via|                tipo|         descricao|              auto|              moto|ciclom|           ciclista|           pedestre|             onibus|           caminhao|           viatura|             outros|            vitimas|vitimasfatais|acidente_verificado|tempo_clima|situacao_semaforo|    sinalizacao|condicao_via|conservacao_via|ponto_controle|situacao_placa|velocidade_max_via|mao_direcao|divisao_via1|divisao_via2|divisao_via3|\n",
            "+-------+--------+-----------------+---------+---------+-------------------+------------------+-------------------------+--------------------+-------------------+------------------+---------------------+-----------------+------------------+-----------------+--------------------+------------------+------------------+------------------+------+-------------------+-------------------+-------------------+-------------------+------------------+-------------------+-------------------+-------------+-------------------+-----------+-----------------+---------------+------------+---------------+--------------+--------------+------------------+-----------+------------+------------+------------+\n",
            "|  count|   12046|            12058|    12058|    11914|              12009|              6013|                     4308|                9609|              12002|              6011|                 9606|            11909|              3029|             8293|               12062|             11762|             11140|              2904|    48|                224|                255|               1811|               1224|               122|                210|              12035|           25|               9191|       9706|             9581|           9524|        9673|           9525|          8670|          8733|              2858|       9522|        9130|         908|         150|\n",
            "|   mean|    NULL|             NULL|     NULL|     NULL|               NULL| 1184.249320652174|                     NULL|             2334.75|               NULL|1183.8995922528034|              2334.75|     9.98434034E8|289.15450643776825|           135.25|                NULL|              NULL|1.5841113105924596|1.0561294765840221|   1.0| 1.0089285714285714| 1.0509803921568628| 1.0209828823854223| 1.0212418300653594|1.0245901639344261|  1.061904761904762|0.21545492314083922|          1.0|               NULL|       NULL|             NULL|           NULL|        NULL|           NULL|          NULL|          NULL|              NULL|       NULL|        NULL|        NULL|        NULL|\n",
            "| stddev|    NULL|             NULL|     NULL|     NULL|               NULL|1527.5017701756722|                     NULL|   2635.866761301362|               NULL|1527.1183559269984|    2635.866761301362|             NULL| 217.6663272461742|76.97781065562552|                NULL|              NULL|0.6177047673742271|0.2433057550274722|   0.0|0.09427901670929757|0.23758342837999133|0.14336649028121842|0.15517171249419665| 0.155511140899212|0.24155831906253245|  0.490081563481564|          0.0|               NULL|       NULL|             NULL|           NULL|        NULL|           NULL|          NULL|          NULL|              NULL|       NULL|        NULL|        NULL|        NULL|\n",
            "|    min|00:00:00|            APOIO|CANCELADA|  AFLITOS|1 TRV JUSTICA E PAZ|            0940 A|      1 TRV JUSTICA E PAZ|10 METROS ANTES C...|1 TRV JUSTICA E PAZ|            0940 A| 10 METROS ANTES C...|        998434034|                 1|              191|ABALROAMENTO LONG...|   ,MOTO X CLASSIC|                 0|                 0|     1|                  1|                  1|                  1|                  0|                 1|                  1|                  0|            1|         Cruzamento|        Bom|      Com defeito|       Ilegível|     Molhada| Mal conservada|        Agente|         A-33a|           10 km/h|      Dupla|      Blocos|      Blocos|      Blocos|\n",
            "|    max|48:00:00|     VÍTIMA FATAL| PENDENTE|ÁGUA FRIA|           av norte|                 \\|     VIADUTO TANCREDO ...|ÁREA INTERNA DO S...|           av norte|                 \\| ÁREA INTERNA DO S...|        ÁGUA FRIA|              4038|        ÁGUA FRIA|          TOMBAMENTO|ÕNIBUS X AUTO. S/V|                 6|                 4|     1|                  2|                  3|                  2|                  2|                 2|                  2|                  7|            1|            Viaduto|    Nublado|      Sem defeito|Perfeito estado|        Seca|Perfeito estado|        Outros|          R-6c|           60 km/h|      Única|      Outros|      Outros|      Outros|\n",
            "+-------+--------+-----------------+---------+---------+-------------------+------------------+-------------------------+--------------------+-------------------+------------------+---------------------+-----------------+------------------+-----------------+--------------------+------------------+------------------+------------------+------+-------------------+-------------------+-------------------+-------------------+------------------+-------------------+-------------------+-------------+-------------------+-----------+-----------------+---------------+------------+---------------+--------------+--------------+------------------+-----------+------------+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "data_dir = 'data/'\n",
        "\n",
        "csv_files = sorted([f for f in os.listdir(data_dir) if f.endswith('.csv')])\n",
        "\n",
        "if not csv_files:\n",
        "  print(\"No CSV files found in the directory 'data/'\")\n",
        "else:\n",
        "  base_path = os.path.join(data_dir, csv_files[0])\n",
        "  base_header = spark.read.option(\"delimiter\", \";\").option(\"header\", \"true\").csv(base_path).columns\n",
        "\n",
        "  equals = True\n",
        "\n",
        "  for f in csv_files[1:]:\n",
        "    current_path = os.path.join(data_dir, f)\n",
        "    current_header = spark.read.option(\"delimiter\", \";\").option(\"header\", \"true\").csv(current_path).columns\n",
        "    if current_header != base_header:\n",
        "      equals = False\n",
        "      print(f\"\\n!!! ALERT: The header of '{f}' is DIFFERENT! Analysis:\")\n",
        "      base_set = set(base_header)\n",
        "      current_set = set(current_header)\n",
        "      removed_columns = base_set - current_set\n",
        "      if removed_columns:\n",
        "          print(f\"  - Missing columns in this file: {list(removed_columns)}\")\n",
        "      added_columns = current_set - base_set\n",
        "      if added_columns:\n",
        "          print(f\"  - Extra columns found in this file: {list(added_columns)}\")\n",
        "      if len(base_header) != len(current_header):\n",
        "            print(f\"  - Column count diverges: {len(base_header)} in reference vs. {len(current_header)} in this file.\") # Translated\n",
        "      print(\"-\" * 30)\n",
        "\n",
        "  if equals:\n",
        "      print(\"\\nGreat news! All CSV files have the same header.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxP8ymJ9uSDe",
        "outputId": "6e3b0945-3227-4a26-cf3b-0d6d72e436aa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "!!! ALERT: The header of 'acidentes_2020.csv' is DIFFERENT! Analysis:\n",
            "  - Missing columns in this file: ['endereco_cruzamento', 'DATA', 'numero_cruzamento', 'referencia_cruzamento']\n",
            "  - Extra columns found in this file: ['data']\n",
            "  - Column count diverges: 41 in reference vs. 38 in this file.\n",
            "------------------------------\n",
            "\n",
            "!!! ALERT: The header of 'acidentes_2021.csv' is DIFFERENT! Analysis:\n",
            "  - Missing columns in this file: ['numero_cruzamento', 'DATA', 'endereco_cruzamento', 'descricao', 'referencia_cruzamento']\n",
            "  - Extra columns found in this file: ['data']\n",
            "  - Column count diverges: 41 in reference vs. 37 in this file.\n",
            "------------------------------\n",
            "\n",
            "!!! ALERT: The header of 'acidentes_2022.csv' is DIFFERENT! Analysis:\n",
            "  - Missing columns in this file: ['numero_cruzamento', 'DATA', 'endereco_cruzamento', 'descricao', 'natureza_acidente', 'referencia_cruzamento']\n",
            "  - Extra columns found in this file: ['natureza', 'Protocolo', 'data']\n",
            "  - Column count diverges: 41 in reference vs. 38 in this file.\n",
            "------------------------------\n",
            "\n",
            "!!! ALERT: The header of 'acidentes_2023.csv' is DIFFERENT! Analysis:\n",
            "  - Missing columns in this file: ['numero_cruzamento', 'DATA', 'endereco_cruzamento', 'descricao', 'natureza_acidente', 'referencia_cruzamento']\n",
            "  - Extra columns found in this file: ['natureza', 'Protocolo', 'data']\n",
            "  - Column count diverges: 41 in reference vs. 38 in this file.\n",
            "------------------------------\n",
            "\n",
            "!!! ALERT: The header of 'acidentes_2024.csv' is DIFFERENT! Analysis:\n",
            "  - Missing columns in this file: ['numero_cruzamento', 'DATA', 'endereco_cruzamento', 'descricao', 'natureza_acidente', 'referencia_cruzamento']\n",
            "  - Extra columns found in this file: ['natureza', 'Protocolo', 'data']\n",
            "  - Column count diverges: 41 in reference vs. 38 in this file.\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_acidentes2024 = spark.read \\\n",
        "  .option(\"header\", \"true\") \\\n",
        "  .option(\"inferSchema\", \"true\") \\\n",
        "  .option(\"delimiter\", \";\") \\\n",
        "  .csv('data/acidentes_2024.csv')\n",
        "\n",
        "df_acidentes2024.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaPigv8DF3QQ",
        "outputId": "bdc946a5-ae6b-467a-9c20-12caed2e2400"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+------------+----------+-------+--------------------+-----------------+-------------------------+--------------------+-----------------+------------+-----------+--------------------+----+----+------+--------+--------+------+--------+-------+------+-------+-------------+-------------------+-----------+-----------------+-----------+------------+---------------+--------------+--------------+------------------+-----------+------------+------------+------------+\n",
            "|summary|  Protocolo|    natureza|  situacao| bairro|            endereco|           numero|detalhe_endereco_acidente|         complemento|bairro_cruzamento|num_semaforo|sentido_via|                tipo|auto|moto|ciclom|ciclista|pedestre|onibus|caminhao|viatura|outros|vitimas|vitimasfatais|acidente_verificado|tempo_clima|situacao_semaforo|sinalizacao|condicao_via|conservacao_via|ponto_controle|situacao_placa|velocidade_max_via|mao_direcao|divisao_via1|divisao_via2|divisao_via3|\n",
            "+-------+-----------+------------+----------+-------+--------------------+-----------------+-------------------------+--------------------+-----------------+------------+-----------+--------------------+----+----+------+--------+--------+------+--------+-------+------+-------+-------------+-------------------+-----------+-----------------+-----------+------------+---------------+--------------+--------------+------------------+-----------+------------+------------+------------+\n",
            "|  count|       5315|        5315|      5315|   5308|                5297|             2419|                      698|                5036|             5308|         199|        377|                5285|5315|5315|  5315|    5315|    5315|  5315|    5315|   5315|  5315|   5315|         5315|                  0|          0|                0|          0|           0|              0|             0|             0|                 0|          0|           0|           0|           0|\n",
            "|   mean|       NULL|        NULL|      NULL|   NULL|                NULL|1425.840475180314|                     NULL|                NULL|             NULL|        NULL|     1987.0|                NULL|NULL|NULL|  NULL|    NULL|    NULL|  NULL|    NULL|   NULL|  NULL|   NULL|         NULL|               NULL|       NULL|             NULL|       NULL|        NULL|           NULL|          NULL|          NULL|              NULL|       NULL|        NULL|        NULL|        NULL|\n",
            "| stddev|       NULL|        NULL|      NULL|   NULL|                NULL|2193.806380777639|                     NULL|                NULL|             NULL|        NULL|       NULL|                NULL|NULL|NULL|  NULL|    NULL|    NULL|  NULL|    NULL|   NULL|  NULL|   NULL|         NULL|               NULL|       NULL|             NULL|       NULL|        NULL|           NULL|          NULL|          NULL|              NULL|       NULL|        NULL|        NULL|        NULL|\n",
            "|    min|202406373,0|  COM VÍTIMA| CANCELADA|AFLITOS|1 TRV DOUTOR SABI...|                1|     1 TRV DOUTOR SABI...|( JORDÃO BAIXO ),...|          AFLITOS|       100,0|       1987|ATROPELAMENTO DE ...| 0,0| 0,0|   0,0|     0,0|     0,0|   0,0|     0,0|    0,0|   0,0|    0,0|          0,0|               NULL|       NULL|             NULL|       NULL|        NULL|           NULL|          NULL|          NULL|              NULL|       NULL|        NULL|        NULL|        NULL|\n",
            "|    max|   299315,0|VÍTIMA FATAL|FINALIZADA|  ZUMBI|VIADUTO ULYSSES G...|               SN|     VDO PAPA JOAO PAU...|sobre a ponte Jos...|            ZUMBI|        96,0|   SUBURBIO|          TOMBAMENTO| 4,0| 3,0|   1,0|     2,0|     2,0|   2,0|     2,0|    2,0|  24,0|    4,0|          6,0|               NULL|       NULL|             NULL|       NULL|        NULL|           NULL|          NULL|          NULL|              NULL|       NULL|        NULL|        NULL|        NULL|\n",
            "+-------+-----------+------------+----------+-------+--------------------+-----------------+-------------------------+--------------------+-----------------+------------+-----------+--------------------+----+----+------+--------+--------+------+--------+-------+------+-------+-------------+-------------------+-----------+-----------------+-----------+------------+---------------+--------------+--------------+------------------+-----------+------------+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Definição do Schema Unificado (Unified Schema Definition)\n",
        "\n",
        "Com base na análise, definimos um **schema unificado e explícito** usando `StructType`. Este schema representa o \"superconjunto\" de todas as colunas encontradas em todos os arquivos, padronizando os nomes (ex: `DATA` para `data`) e definindo os tipos de dados corretos. Manter todas as colunas como `nullable=True` nesta etapa garante que a ingestão não falhe por dados faltantes na origem."
      ],
      "metadata": {
        "id": "9BBIyqqktrns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, DateType, IntegerType\n",
        "\n",
        "unified_schema = StructType([\n",
        "  StructField('data', DateType(), True),\n",
        "  StructField('hora', StringType(), True),\n",
        "  StructField('natureza_acidente', StringType(), True),\n",
        "  StructField('situacao', StringType(), True),\n",
        "  StructField('protocolo', StringType(), True),\n",
        "\n",
        "  StructField('bairro', StringType(), True),\n",
        "  StructField('endereco', StringType(), True),\n",
        "  StructField('numero', StringType(), True),\n",
        "\n",
        "  StructField('detalhe_endereco_acidente', StringType(), True),\n",
        "  StructField('complemento', StringType(), True),\n",
        "  StructField('endereco_cruzamento', StringType(), True),\n",
        "  StructField('numero_cruzamento', StringType(), True),\n",
        "  StructField('referencia_cruzamento', StringType(), True),\n",
        "  StructField('bairro_cruzamento', StringType(), True),\n",
        "  StructField('num_semaforo', IntegerType(), True),\n",
        "  StructField('sentido_via', StringType(), True),\n",
        "  StructField('tipo', StringType(), True),\n",
        "  StructField('descricao', StringType(), True),\n",
        "\n",
        "  StructField('auto', IntegerType(), True),\n",
        "  StructField('moto', IntegerType(), True),\n",
        "  StructField('ciclom', IntegerType(), True),\n",
        "  StructField('ciclista', IntegerType(), True),\n",
        "  StructField('pedestre', IntegerType(), True),\n",
        "  StructField('onibus', IntegerType(), True),\n",
        "  StructField('caminhao', IntegerType(), True),\n",
        "  StructField('viatura', IntegerType(), True),\n",
        "  StructField('outros', IntegerType(), True),\n",
        "  StructField('vitimas', IntegerType(), True),\n",
        "  StructField('vitimas_fatais', IntegerType(), True),\n",
        "\n",
        "  StructField('acidente_verificado', StringType(), True),\n",
        "  StructField('tempo_clima', StringType(), True),\n",
        "  StructField('situacao_semaforo', StringType(), True),\n",
        "  StructField('sinalizacao', StringType(), True),\n",
        "  StructField('condicao_via', StringType(), True),\n",
        "  StructField('conservacao_via', StringType(), True),\n",
        "  StructField('ponto_controle', StringType(), True),\n",
        "  StructField('situacao_placa', StringType(), True),\n",
        "  StructField('velocidade_max_via', IntegerType(), True),\n",
        "  StructField('mao_direcao', StringType(), True),\n",
        "\n",
        "  StructField('divisao_via1', StringType(), True),\n",
        "  StructField('divisao_via2', StringType(), True),\n",
        "  StructField('divisao_via3', StringType(), True)\n",
        "\n",
        "])\n",
        "\n",
        "schema_columns = unified_schema.names\n",
        "print(f\"Your Schema have {len(schema_columns)} columns.\")\n",
        "print(unified_schema)"
      ],
      "metadata": {
        "id": "pukidjastueN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf1a5b16-fd59-4fef-a7c6-49b6dbae5548"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your Schema have 42 columns.\n",
            "StructType([StructField('data', DateType(), True), StructField('hora', StringType(), True), StructField('natureza_acidente', StringType(), True), StructField('situacao', StringType(), True), StructField('protocolo', StringType(), True), StructField('bairro', StringType(), True), StructField('endereco', StringType(), True), StructField('numero', StringType(), True), StructField('detalhe_endereco_acidente', StringType(), True), StructField('complemento', StringType(), True), StructField('endereco_cruzamento', StringType(), True), StructField('numero_cruzamento', StringType(), True), StructField('referencia_cruzamento', StringType(), True), StructField('bairro_cruzamento', StringType(), True), StructField('num_semaforo', IntegerType(), True), StructField('sentido_via', StringType(), True), StructField('tipo', StringType(), True), StructField('descricao', StringType(), True), StructField('auto', IntegerType(), True), StructField('moto', IntegerType(), True), StructField('ciclom', IntegerType(), True), StructField('ciclista', IntegerType(), True), StructField('pedestre', IntegerType(), True), StructField('onibus', IntegerType(), True), StructField('caminhao', IntegerType(), True), StructField('viatura', IntegerType(), True), StructField('outros', IntegerType(), True), StructField('vitimas', IntegerType(), True), StructField('vitimas_fatais', IntegerType(), True), StructField('acidente_verificado', StringType(), True), StructField('tempo_clima', StringType(), True), StructField('situacao_semaforo', StringType(), True), StructField('sinalizacao', StringType(), True), StructField('condicao_via', StringType(), True), StructField('conservacao_via', StringType(), True), StructField('ponto_controle', StringType(), True), StructField('situacao_placa', StringType(), True), StructField('velocidade_max_via', IntegerType(), True), StructField('mao_direcao', StringType(), True), StructField('divisao_via1', StringType(), True), StructField('divisao_via2', StringType(), True), StructField('divisao_via3', StringType(), True)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_dir = 'data'\n",
        "all_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.csv')])\n",
        "\n",
        "all_headers = set()\n",
        "\n",
        "for file_path in all_files:\n",
        "  header = spark.read.option(\"delimiter\", \";\").option(\"header\", \"true\").csv(file_path).columns\n",
        "  all_headers.update(header)\n",
        "\n",
        "unique_column_list = sorted(list(all_headers))\n",
        "\n",
        "print(f\"Found {len(unique_column_list)} unique columns across all files:\")\n",
        "print(unique_column_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCAqyZft6bW8",
        "outputId": "d7dfe80b-abe5-42ca-8b67-243b4e29f83f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 44 unique columns across all files:\n",
            "['DATA', 'Protocolo', 'acidente_verificado', 'auto', 'bairro', 'bairro_cruzamento', 'caminhao', 'ciclista', 'ciclom', 'complemento', 'condicao_via', 'conservacao_via', 'data', 'descricao', 'detalhe_endereco_acidente', 'divisao_via1', 'divisao_via2', 'divisao_via3', 'endereco', 'endereco_cruzamento', 'hora', 'mao_direcao', 'moto', 'natureza', 'natureza_acidente', 'num_semaforo', 'numero', 'numero_cruzamento', 'onibus', 'outros', 'pedestre', 'ponto_controle', 'referencia_cruzamento', 'sentido_via', 'sinalizacao', 'situacao', 'situacao_placa', 'situacao_semaforo', 'tempo_clima', 'tipo', 'velocidade_max_via', 'viatura', 'vitimas', 'vitimasfatais']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_columns_standardized = [header.lower() for header in unique_column_list]\n",
        "print(f\"The source files have {len(source_columns_standardized)} unique standardized columns.\")\n",
        "\n",
        "extra_columns = set(schema_columns) - set(source_columns_standardized)\n",
        "if extra_columns:\n",
        "  print(f\"The extra columns are: {extra_columns}\")\n",
        "else:\n",
        "  print(\"No extra columns found.\")\n",
        "\n",
        "over_columns = set(source_columns_standardized) - set(schema_columns)\n",
        "if over_columns:\n",
        "  print(f\"The missing columns are: {over_columns}\")\n",
        "else:\n",
        "  print(\"No missing columns found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95F7s0XIHjqY",
        "outputId": "ce14cdc4-24aa-4b2d-fd7f-546cbad82003"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source files have 44 unique standardized columns.\n",
            "The extra columns are: {'vitimas_fatais'}\n",
            "The missing columns are: {'natureza', 'vitimasfatais'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3. Carga, Mapeamento e Enriquecimento (Ingestion, Mapping & Enrichment)\n",
        "\n",
        "Implementamos um loop para processar cada arquivo CSV. Para lidar com o Schema Drift, utilizamos o padrão **\"Read, Rename, and UnionByName\"**:\n",
        "1.  **Read:** Lemos cada arquivo individualmente, deixando o Spark inferir os nomes originais do cabeçalho.\n",
        "2.  **Rename:** Renomeamos as colunas inconsistentes para se alinharem ao nosso schema padrão.\n",
        "3.  **UnionByName:** Unimos o DataFrame tratado ao DataFrame final, alinhando as colunas pelo nome.\n",
        "\n",
        "Além disso, enriquecemos os dados com duas colunas de metadados essenciais:\n",
        "- `source_file`: Para rastreabilidade da origem de cada registro.\n",
        "- `year`: Para permitir o particionamento da tabela."
      ],
      "metadata": {
        "id": "RCx_RwdeLJlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bronze_final = spark.createDataFrame([], unified_schema)"
      ],
      "metadata": {
        "id": "rR8_6wRqnbUF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'data'\n",
        "all_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.csv')])\n",
        "\n",
        "for file_path in all_files:\n",
        "    df_raw = spark.read.option(\"header\", \"true\").option(\"delimiter\", \";\").option('inferSchema', True).csv(file_path)\n",
        "\n",
        "    df_renamed = df_raw.withColumnRenamed('DATA','data') \\\n",
        "                       .withColumnRenamed('natureza', 'natureza_acidente') \\\n",
        "                       .withColumnRenamed('vitimasfatais', 'vitimas_fatais') \\\n",
        "                       .withColumnRenamed('Protocolo', 'protocolo')\n",
        "\n",
        "    df_bronze_final = df_bronze_final.unionByName(df_renamed, allowMissingColumns=True)"
      ],
      "metadata": {
        "id": "7pe0_W81L98C"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df_columns = df_bronze_final.columns\n",
        "\n",
        "expected_schema_columns = unified_schema.names\n",
        "\n",
        "missing_columns = set(expected_schema_columns) - set(final_df_columns)\n",
        "extra_columns = set(final_df_columns) - set(expected_schema_columns)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"Final Schema Validation Report\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "if not missing_columns and not extra_columns:\n",
        "    print(f\"✅ SUCCESS! The final DataFrame schema perfectly matches the expected unified schema.\")\n",
        "    print(f\"Total columns loaded: {len(final_df_columns)}\")\n",
        "else:\n",
        "    print(\"⚠️ ATTENTION: Discrepancy found!\")\n",
        "    if missing_columns:\n",
        "        print(f\"  - Columns defined in schema but MISSING from final DataFrame: {list(missing_columns)}\")\n",
        "    if extra_columns:\n",
        "        print(f\"  - EXTRA columns found in final DataFrame that were not in schema: {list(extra_columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDoZTpido5oT",
        "outputId": "c180dbe6-9640-412b-85d9-686cb3a0c3a8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "Final Schema Validation Report\n",
            "==================================================\n",
            "✅ SUCCESS! The final DataFrame schema perfectly matches the expected unified schema.\n",
            "Total columns loaded: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import input_file_name, year, col\n",
        "\n",
        "\n",
        "df_bronze_with_metadata = df_bronze_final \\\n",
        "  .withColumn('source_file', input_file_name()) \\\n",
        "  .withColumn('year', year(col('data')))\n",
        "\n",
        "print(\"DataFrame with source_file metadata column:\")\n",
        "df_bronze_with_metadata.select(\"data\", \"bairro\", \"source_file\", \"year\").show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MVHFf6BuFlx",
        "outputId": "b4a024f7-149b-4b1d-d678-50aa3cf91332"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with source_file metadata column:\n",
            "+----------+-----------+---------------------------------------+----+\n",
            "|data      |bairro     |source_file                            |year|\n",
            "+----------+-----------+---------------------------------------+----+\n",
            "|2019-01-01|IPSEP      |file:///content/data/acidentes_2019.csv|2019|\n",
            "|2019-01-01|BOA VIAGEM |file:///content/data/acidentes_2019.csv|2019|\n",
            "|2019-01-01|BOA VIAGEM |file:///content/data/acidentes_2019.csv|2019|\n",
            "|2019-01-01|IMBIRIBEIRA|file:///content/data/acidentes_2019.csv|2019|\n",
            "|2019-01-01|JAQUEIRA   |file:///content/data/acidentes_2019.csv|2019|\n",
            "+----------+-----------+---------------------------------------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4. Salvando a Tabela Bronze (Saving the Bronze Table)\n",
        "\n",
        "Finalmente, salvamos o DataFrame unificado e enriquecido como uma tabela Delta, que é a base do nosso Lakehouse. A tabela é salva no modo `overwrite` e **particionada por ano** (`partitionBy(\"year\")`) para otimizar drasticamente a performance de futuras consultas que filtrem por data.*texto em itálico*"
      ],
      "metadata": {
        "id": "wwPnej8P7ZeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bronze_table_path = \"delta_lake/bronze/acidentes\"\n",
        "\n",
        "print(\"Saving Bronze table...\")\n",
        "\n",
        "df_bronze_with_metadata.write \\\n",
        "    .format(\"delta\") \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .partitionBy(\"year\") \\\n",
        "    .save(bronze_table_path)\n",
        "\n",
        "print(f\"SUCCESS: Bronze table saved successfully to '{bronze_table_path}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asGlciWX245_",
        "outputId": "71fef02e-9312-475f-85d7-53d2007fef87"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Bronze table...\n",
            "SUCCESS: Bronze table saved successfully to 'delta_lake/bronze/acidentes'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusão da Camada Bronze\n",
        "\n",
        "A Camada Bronze está completa! Nossos dados brutos de múltiplos arquivos inconsistentes estão agora armazenados em uma única tabela Delta, com schema unificado, metadados de linhagem e otimizada para leitura com particionamento.\n",
        "\n",
        "**Próximo Passo:** Iniciar a **Camada Silver**, onde vamos limpar, validar e enriquecer estes dados."
      ],
      "metadata": {
        "id": "8TE3egVP7hwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Camada Silver: Limpeza e Enriquecimento de Dados\n",
        "\n",
        "Iniciamos a Camada Silver, o coração do nosso processo de ETL. O objetivo aqui é transformar os dados brutos e não confiáveis da Camada Bronze em uma fonte de dados limpa, consistente e enriquecida, pronta para análises mais complexas. Aplicaremos regras de negócio e técnicas de limpeza para garantir a **Qualidade e Governança dos Dados**, como defendido por **Reis & Housley** e **Kimball**."
      ],
      "metadata": {
        "id": "sxAbNZl6jB2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1. Leitura da Tabela Bronze\n",
        "\n",
        "O primeiro passo é carregar nossa tabela Delta da Camada Bronze. Esta ação representa o início do pipeline que move os dados entre as camadas Bronze e Silver."
      ],
      "metadata": {
        "id": "2uIojVnMGvox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_silver = spark.read.format(\"delta\").load(bronze_table_path)\n",
        "\n",
        "print(\"Reading from Bronze Delta table to start the Silver process...\")\n",
        "df_silver.printSchema()\n",
        "print(f\"\\nTotal records read from Bronze: {df_silver.count()}\")\n",
        "df_silver.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJKxCqPojBQN",
        "outputId": "a7456287-692e-4fac-94a7-43a1f83e5802"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading from Bronze Delta table to start the Silver process...\n",
            "root\n",
            " |-- data: date (nullable = true)\n",
            " |-- hora: string (nullable = true)\n",
            " |-- natureza_acidente: string (nullable = true)\n",
            " |-- situacao: string (nullable = true)\n",
            " |-- protocolo: string (nullable = true)\n",
            " |-- bairro: string (nullable = true)\n",
            " |-- endereco: string (nullable = true)\n",
            " |-- numero: string (nullable = true)\n",
            " |-- detalhe_endereco_acidente: string (nullable = true)\n",
            " |-- complemento: string (nullable = true)\n",
            " |-- endereco_cruzamento: string (nullable = true)\n",
            " |-- numero_cruzamento: string (nullable = true)\n",
            " |-- referencia_cruzamento: string (nullable = true)\n",
            " |-- bairro_cruzamento: string (nullable = true)\n",
            " |-- num_semaforo: string (nullable = true)\n",
            " |-- sentido_via: string (nullable = true)\n",
            " |-- tipo: string (nullable = true)\n",
            " |-- descricao: string (nullable = true)\n",
            " |-- auto: string (nullable = true)\n",
            " |-- moto: string (nullable = true)\n",
            " |-- ciclom: string (nullable = true)\n",
            " |-- ciclista: string (nullable = true)\n",
            " |-- pedestre: string (nullable = true)\n",
            " |-- onibus: string (nullable = true)\n",
            " |-- caminhao: string (nullable = true)\n",
            " |-- viatura: string (nullable = true)\n",
            " |-- outros: string (nullable = true)\n",
            " |-- vitimas: string (nullable = true)\n",
            " |-- vitimas_fatais: string (nullable = true)\n",
            " |-- acidente_verificado: string (nullable = true)\n",
            " |-- tempo_clima: string (nullable = true)\n",
            " |-- situacao_semaforo: string (nullable = true)\n",
            " |-- sinalizacao: string (nullable = true)\n",
            " |-- condicao_via: string (nullable = true)\n",
            " |-- conservacao_via: string (nullable = true)\n",
            " |-- ponto_controle: string (nullable = true)\n",
            " |-- situacao_placa: string (nullable = true)\n",
            " |-- velocidade_max_via: string (nullable = true)\n",
            " |-- mao_direcao: string (nullable = true)\n",
            " |-- divisao_via1: string (nullable = true)\n",
            " |-- divisao_via2: string (nullable = true)\n",
            " |-- divisao_via3: string (nullable = true)\n",
            " |-- source_file: string (nullable = true)\n",
            " |-- year: integer (nullable = true)\n",
            "\n",
            "\n",
            "Total records read from Bronze: 30550\n",
            "+----------+-------------------+-----------------+----------+-----------+----------+--------------------+------+-------------------------+--------------------+-------------------+-----------------+---------------------+-----------------+------------+-----------+--------------------+---------+----+----+------+--------+--------+------+--------+-------+------+-------+--------------+-------------------+-----------+-----------------+-----------+------------+---------------+--------------+--------------+------------------+-----------+------------+------------+------------+--------------------+----+\n",
            "|      data|               hora|natureza_acidente|  situacao|  protocolo|    bairro|            endereco|numero|detalhe_endereco_acidente|         complemento|endereco_cruzamento|numero_cruzamento|referencia_cruzamento|bairro_cruzamento|num_semaforo|sentido_via|                tipo|descricao|auto|moto|ciclom|ciclista|pedestre|onibus|caminhao|viatura|outros|vitimas|vitimas_fatais|acidente_verificado|tempo_clima|situacao_semaforo|sinalizacao|condicao_via|conservacao_via|ponto_controle|situacao_placa|velocidade_max_via|mao_direcao|divisao_via1|divisao_via2|divisao_via3|         source_file|year|\n",
            "+----------+-------------------+-----------------+----------+-----------+----------+--------------------+------+-------------------------+--------------------+-------------------+-----------------+---------------------+-----------------+------------+-----------+--------------------+---------+----+----+------+--------+--------+------+--------+-------+------+-------+--------------+-------------------+-----------+-----------------+-----------+------------+---------------+--------------+--------------+------------------+-----------+------------+------------+------------+--------------------+----+\n",
            "|2023-01-01|2025-10-04 03:37:00|       COM VÍTIMA|FINALIZADA|202300005,0|  MADALENA|AV ENGENHEIRO ABD...|   167|                     NULL|E/F AO POSTO BR -...|               NULL|             NULL|                 NULL|         MADALENA|        NULL|     CIDADE|ATROPELAMENTO DE ...|     NULL| 1,0| 0,0|   0,0|     0,0|     1,0|   0,0|     0,0|    0,0|   0,0|    1,0|           0,0|               NULL|       NULL|             NULL|       NULL|        NULL|           NULL|          NULL|          NULL|              NULL|       NULL|        NULL|        NULL|        NULL|file:///content/d...|2023|\n",
            "|2023-01-01|2025-10-04 08:28:00|       COM VÍTIMA|FINALIZADA|202300009,0|     BONGI|AV ENGENHEIRO ABD...|   758|         RUA CARLOS GOMES|EM FRENTE AO POST...|               NULL|             NULL|                 NULL|            BONGI|        NULL|   SUBURBIO|     COLISÃO LATERAL|     NULL| 0,0| 2,0|   0,0|     0,0|     0,0|   0,0|     0,0|    0,0|   0,0|    2,0|           0,0|               NULL|       NULL|             NULL|       NULL|        NULL|           NULL|          NULL|          NULL|              NULL|       NULL|        NULL|        NULL|        NULL|file:///content/d...|2023|\n",
            "|2023-01-01|2025-10-04 10:39:00|       COM VÍTIMA|FINALIZADA|202300019,0|  JAQUEIRA|   RUA MUNIZ TAVARES|  NULL|           AV RUI BARBOSA|DE ESQUINA COM O ...|               NULL|             NULL|                 NULL|         JAQUEIRA|       460,0|     CIDADE|     COLISÃO LATERAL|     NULL| 1,0| 1,0|   0,0|     0,0|     0,0|   0,0|     0,0|    0,0|   0,0|    1,0|           0,0|               NULL|       NULL|             NULL|       NULL|        NULL|           NULL|          NULL|          NULL|              NULL|       NULL|        NULL|        NULL|        NULL|file:///content/d...|2023|\n",
            "|2023-01-01|2025-10-04 12:41:00|       SEM VÍTIMA|FINALIZADA|202300022,0|BOA VIAGEM|       AV BOA VIAGEM|   457|                     NULL|PROX AO SEMAFORO ...|               NULL|             NULL|                 NULL|       BOA VIAGEM|        NULL|       NULL|    COLISÃO TRASEIRA|     NULL| 2,0| 0,0|   0,0|     0,0|     0,0|   0,0|     0,0|    0,0|   0,0|    0,0|           0,0|               NULL|       NULL|             NULL|       NULL|        NULL|           NULL|          NULL|          NULL|              NULL|       NULL|        NULL|        NULL|        NULL|file:///content/d...|2023|\n",
            "|2023-01-01|2025-10-04 03:44:00|       COM VÍTIMA|FINALIZADA|202300037,0|BOA VIAGEM|AV ENGENHEIRO DOM...|  1971|                     NULL|PROX A  PRAÇA CID...|               NULL|             NULL|                 NULL|       BOA VIAGEM|        NULL|       NULL|ATROPELAMENTO DE ...|     NULL| 1,0| 0,0|   0,0|     0,0|     1,0|   0,0|     0,0|    0,0|   0,0|    1,0|           0,0|               NULL|       NULL|             NULL|       NULL|        NULL|           NULL|          NULL|          NULL|              NULL|       NULL|        NULL|        NULL|        NULL|file:///content/d...|2023|\n",
            "+----------+-------------------+-----------------+----------+-----------+----------+--------------------+------+-------------------------+--------------------+-------------------+-----------------+---------------------+-----------------+------------+-----------+--------------------+---------+----+----+------+--------+--------+------+--------+-------+------+-------+--------------+-------------------+-----------+-----------------+-----------+------------+---------------+--------------+--------------+------------------+-----------+------------+------------+------------+--------------------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2. Limpeza e Padronização de Dados (Data Cleaning)\n",
        "\n",
        "Esta etapa foca em melhorar a qualidade e a consistência dos dados. Seguindo as práticas de **Limpeza de Dados** de **McKinney**, aplicamos duas transformações essenciais:\n",
        "\n",
        "* **Padronização de Case:** Convertemos colunas categóricas de texto para maiúsculas (`UPPERCASE`). Isso garante que valores como \"Boa Viagem\" e \"BOA VIAGEM\" sejam tratados como um só, um processo que **Kimball** chama de \"conformar atributos de dimensão\".\n",
        "* **Tratamento de Nulos:** Substituímos valores `NULL` em colunas categóricas importantes (como `bairro`) por um valor explícito (`'NAO INFORMADO'`). Isso torna o dado menos ambíguo e mais fácil de ser consumido por ferramentas de BI."
      ],
      "metadata": {
        "id": "c1gNLp1zkTig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import upper, col\n",
        "\n",
        "df_temp = df_silver \\\n",
        "  .withColumn('bairro', upper(col('bairro'))) \\\n",
        "\n",
        "print(\"Verifying the standardization of the 'bairro' column:\")\n",
        "df_temp.select(\"bairro\").show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGyNskFdkXwD",
        "outputId": "5ae5c21e-a559-476f-fc30-183d2f0f02a5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verifying the standardization of the 'bairro' column:\n",
            "+----------+\n",
            "|bairro    |\n",
            "+----------+\n",
            "|MADALENA  |\n",
            "|BONGI     |\n",
            "|JAQUEIRA  |\n",
            "|BOA VIAGEM|\n",
            "|BOA VIAGEM|\n",
            "+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_upper = ['natureza_acidente', 'situacao', 'bairro', 'endereco', 'bairro_cruzamento', 'sentido_via', 'tipo', 'tempo_clima', 'mao_direcao']\n",
        "\n",
        "df_silver_casing = df_silver\n",
        "for col_name in columns_to_upper:\n",
        "    df_silver_casing = df_silver_casing.withColumn(col_name, upper(col(col_name)))\n",
        "\n",
        "print(\"Verification of the loop transformation:\")\n",
        "df_silver_casing.select(columns_to_upper).show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC0-PwPEotxC",
        "outputId": "5842e616-b59c-4fea-baaa-c2c594596903"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verification of the loop transformation:\n",
            "+-----------------+----------+----------+--------------------------------+-----------------+-----------+-----------------------+-----------+-----------+\n",
            "|natureza_acidente|situacao  |bairro    |endereco                        |bairro_cruzamento|sentido_via|tipo                   |tempo_clima|mao_direcao|\n",
            "+-----------------+----------+----------+--------------------------------+-----------------+-----------+-----------------------+-----------+-----------+\n",
            "|COM VÍTIMA       |FINALIZADA|MADALENA  |AV ENGENHEIRO ABDIAS DE CARVALHO|MADALENA         |CIDADE     |ATROPELAMENTO DE PESSOA|NULL       |NULL       |\n",
            "|COM VÍTIMA       |FINALIZADA|BONGI     |AV ENGENHEIRO ABDIAS DE CARVALHO|BONGI            |SUBURBIO   |COLISÃO LATERAL        |NULL       |NULL       |\n",
            "|COM VÍTIMA       |FINALIZADA|JAQUEIRA  |RUA MUNIZ TAVARES               |JAQUEIRA         |CIDADE     |COLISÃO LATERAL        |NULL       |NULL       |\n",
            "|SEM VÍTIMA       |FINALIZADA|BOA VIAGEM|AV BOA VIAGEM                   |BOA VIAGEM       |NULL       |COLISÃO TRASEIRA       |NULL       |NULL       |\n",
            "|COM VÍTIMA       |FINALIZADA|BOA VIAGEM|AV ENGENHEIRO DOMINGOS FERREIRA |BOA VIAGEM       |NULL       |ATROPELAMENTO DE PESSOA|NULL       |NULL       |\n",
            "+-----------------+----------+----------+--------------------------------+-----------------+-----------+-----------------------+-----------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp = df_silver_casing.na.fill('NÃO INFORMADO', ['bairro'])\n",
        "\n",
        "print(\"\\nVerification of null handling:\")\n",
        "df_temp.filter(col(\"bairro\") == \"NAO INFORMADO\").select(\"data\", \"endereco\", \"bairro\").show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wuWhy40r03b",
        "outputId": "c95b38f0-d3b5-4936-b8c1-e690ec08dcbb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Verification of null handling:\n",
            "+----+--------+------+\n",
            "|data|endereco|bairro|\n",
            "+----+--------+------+\n",
            "+----+--------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subset = ['natureza_acidente', 'situacao', 'bairro', 'sentido_via', 'tipo']\n",
        "\n",
        "df_silver_nulls_handled = df_silver_casing.na.fill('NÃO INFORMADO', subset)"
      ],
      "metadata": {
        "id": "ArUGUCblwra7"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nVerification of null handling:\")\n",
        "df_silver_nulls_handled.filter(col('situacao') == 'NÃO INFORMADO').select(subset).show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StU5p4O0xlk4",
        "outputId": "0035cb12-658e-4abb-f79f-3485472156f5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Verification of null handling:\n",
            "+-----------------+-------------+------------------+-------------+-------------------------+\n",
            "|natureza_acidente|situacao     |bairro            |sentido_via  |tipo                     |\n",
            "+-----------------+-------------+------------------+-------------+-------------------------+\n",
            "|NÃO INFORMADO    |NÃO INFORMADO|BOMBA DO HEMETÉRIO|CIDADE       |CHOQUE OBJETO FIXO       |\n",
            "|NÃO INFORMADO    |NÃO INFORMADO|SANTO ANTÔNIO     |SUBURBIO     |ABALROAMENTO LONGITUDINAL|\n",
            "|NÃO INFORMADO    |NÃO INFORMADO|IPUTINGA          |CIDADE       |ABALROAMENTO LONGITUDINAL|\n",
            "|NÃO INFORMADO    |NÃO INFORMADO|IPUTINGA          |CIDADE       |ABALROAMENTO LONGITUDINAL|\n",
            "|NÃO INFORMADO    |NÃO INFORMADO|AFOGADOS          |NÃO INFORMADO|COLISÃO                  |\n",
            "+-----------------+-------------+------------------+-------------+-------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3. Enriquecimento de Dados (Feature Engineering)\n",
        "\n",
        "Nesta fase de **Transformação e Mapeamento (McKinney)**, criamos novas colunas (*features*) que agregam valor analítico e facilitam as consultas.\n",
        "\n",
        "* **Atributos de Data:** A partir da coluna `data`, derivamos `month`, `day_of_month` e `day_of_week`. Este é um passo fundamental na criação de uma futura **Dimensão Calendário (Kimball)**.\n",
        "* **Atributos de Tempo:** Usando lógica condicional (`when/otherwise`), transformamos a coluna `hora` em uma categoria `periodo_do_dia`, o que simplifica análises baseadas em períodos."
      ],
      "metadata": {
        "id": "S_F4r8CPrZCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import month, col\n",
        "\n",
        "df_temp = df_silver_nulls_handled.withColumn('month', month(col('data')))\n",
        "\n",
        "print(\"Verification of the new 'month' column:\")\n",
        "df_temp.select(\"data\", \"month\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbNztmaax8jd",
        "outputId": "db0421a1-1a34-49cb-93df-9d3d11bcd32b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verification of the new 'month' column:\n",
            "+----------+-----+\n",
            "|      data|month|\n",
            "+----------+-----+\n",
            "|2023-01-01|    1|\n",
            "|2023-01-01|    1|\n",
            "|2023-01-01|    1|\n",
            "|2023-01-01|    1|\n",
            "|2023-01-01|    1|\n",
            "+----------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import month, col, date_format, day\n",
        "\n",
        "df_silver_enriched = df_silver_nulls_handled.withColumn('day_of_month', day(col('data'))) \\\n",
        "  .withColumn('month', month(col('data'))) \\\n",
        "  .withColumn('day_of_week', date_format(col('data'), 'E'))"
      ],
      "metadata": {
        "id": "fOcnFsVdy8Oa"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Verification of the new 'columns' column:\")\n",
        "df_silver_enriched.select(\"data\", \"month\", \"day_of_week\", \"day_of_month\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs8pXEtS3fEQ",
        "outputId": "7d45c959-71d0-4ce0-c5dc-060ef0563fac"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verification of the new 'columns' column:\n",
            "+----------+-----+-----------+------------+\n",
            "|      data|month|day_of_week|day_of_month|\n",
            "+----------+-----+-----------+------------+\n",
            "|2023-01-01|    1|        Sun|           1|\n",
            "|2023-01-01|    1|        Sun|           1|\n",
            "|2023-01-01|    1|        Sun|           1|\n",
            "|2023-01-01|    1|        Sun|           1|\n",
            "|2023-01-01|    1|        Sun|           1|\n",
            "+----------+-----+-----------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, hour, when\n",
        "\n",
        "df_silver_final = df_silver_enriched.withColumn(\"periodo_do_dia\",\n",
        "    when((hour(col(\"hora\")) >= 6) & (hour(col(\"hora\")) < 12), \"MANHA\") \\\n",
        "    .when((hour(col(\"hora\")) >= 12) & (hour(col(\"hora\")) < 18), \"TARDE\") \\\n",
        "    .when((hour(col(\"hora\")) >= 18) & (hour(col(\"hora\")) <= 23), \"NOITE\") \\\n",
        "    .otherwise(\"MADRUGADA\")\n",
        ")"
      ],
      "metadata": {
        "id": "7KQRrRtb6hMV"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Verification of the new 'periodo_do_dia' column:\")\n",
        "df_silver_final.groupBy(\"periodo_do_dia\").count().orderBy(\"count\", ascending=False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuODr_US7ytm",
        "outputId": "03a938e1-2e73-469e-a4f6-ec96711f86e8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verification of the new 'periodo_do_dia' column:\n",
            "+--------------+-----+\n",
            "|periodo_do_dia|count|\n",
            "+--------------+-----+\n",
            "|         MANHA|11889|\n",
            "|         TARDE| 8046|\n",
            "|     MADRUGADA| 6565|\n",
            "|         NOITE| 4050|\n",
            "+--------------+-----+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}