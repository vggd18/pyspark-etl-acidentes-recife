{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyOxvKE2GJL9ohapwd4ciTpY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vggd18/pyspark-etl-acidentes-recife/blob/main/etl_acidentes_recife.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Projeto de Data Lakehouse: Acidentes de Trânsito do Recife\n",
        "\n",
        "**Objetivo:** Construir um pipeline de dados completo (ETL) utilizando PySpark e Delta Lake para processar dados abertos de acidentes de trânsito da cidade do Recife. O projeto segue a arquitetura Medalhão (Bronze, Silver, Gold) para criar um Data Lakehouse robusto, otimizado e pronto para análises.\n",
        "\n",
        "**Ferramentas:** PySpark, Delta Lake, Python\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "CKsrA3LRd2Sy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Configuração do Ambiente (Environment Setup)\n",
        "\n",
        "Nesta seção, preparamos nosso ambiente de desenvolvimento no Google Colab, instalando as bibliotecas necessárias e configurando a sessão Spark com suporte ao Delta Lake."
      ],
      "metadata": {
        "id": "YcM2dhRsd438"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Download dos Dados de Origem (Source Data)\n",
        "\n",
        "A primeira etapa do pipeline é a ingestão dos dados brutos. Aqui, fazemos o download dos arquivos CSV anuais (2019-2024) diretamente do [Portal de Dados Abertos da Prefeitura do Recife](http://dados.recife.pe.gov.br/dataset/acidentes-de-transito-com-e-sem-vitimas)."
      ],
      "metadata": {
        "id": "8f4QrjlUhaUV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jr0OGJZGc4z5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9012c27a-3e27-4e7d-a4d7-306639c2b454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive acidentes_2019.csv downloaded successfully.\n",
            "Archive acidentes_2020.csv downloaded successfully.\n",
            "Archive acidentes_2021.csv downloaded successfully.\n",
            "Archive acidentes_2022.csv downloaded successfully.\n",
            "Archive acidentes_2023.csv downloaded successfully.\n",
            "Archive acidentes_2024.csv downloaded successfully.\n",
            "All files downloaded successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "urls = {\n",
        "  \"2019\": \"http://dados.recife.pe.gov.br/dataset/44087d2d-73b5-4ab3-9bd8-78da7436eed1/resource/3531bafe-d47d-415e-b154-a881081ac76c/download/acidentes-2019.csv\",\n",
        "  \"2020\": \"http://dados.recife.pe.gov.br/dataset/44087d2d-73b5-4ab3-9bd8-78da7436eed1/resource/fc1c8460-0406-4fff-b51a-e79205d1f1ab/download/acidentes_2020-novo.csv\",\n",
        "  \"2021\": \"http://dados.recife.pe.gov.br/dataset/44087d2d-73b5-4ab3-9bd8-78da7436eed1/resource/2caa8f41-ccd9-4ea5-906d-f66017d6e107/download/acidentes2021.csv\",\n",
        "  \"2022\": \"http://dados.recife.pe.gov.br/dataset/44087d2d-73b5-4ab3-9bd8-78da7436eed1/resource/971e0228-fa9c-4a42-b360-c842b29d2f56/download/acidentes2022.csv\",\n",
        "  \"2023\": \"http://dados.recife.pe.gov.br/dataset/44087d2d-73b5-4ab3-9bd8-78da7436eed1/resource/d26b864b-0f7b-403e-b142-fd9989acaaf5/download/acidentes2023.csv\",\n",
        "  \"2024\": \"http://dados.recife.pe.gov.br/dataset/44087d2d-73b5-4ab3-9bd8-78da7436eed1/resource/29afbf42-a36c-475c-8b75-761e17e67679/download/acidentes2024.csv\"\n",
        "}\n",
        "\n",
        "output_dir = 'data'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for year, url in urls.items():\n",
        "  file_name = f\"acidentes_{year}.csv\"\n",
        "  file_path =  os.path.join(output_dir, file_name)\n",
        "\n",
        "  response = requests.get(url)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    with open(file_path, 'wb') as file:\n",
        "      file.write(response.content)\n",
        "    print(f\"Archive {file_name} downloaded successfully.\")\n",
        "  else:\n",
        "    print(f\"Failed to download {file_name}. Status code: {response.status_code}\")\n",
        "\n",
        "print(\"All files downloaded successfully.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Inicialização da Sessão Spark (Spark Session)\n",
        "\n",
        "Configuramos uma sessão Spark habilitada para o Delta Lake. Utilizamos a função `configure_spark_with_delta_pip` que garante a correta configuração das dependências Java (JARs), resolvendo os desafios de compatibilidade do ambiente."
      ],
      "metadata": {
        "id": "99x-01frg66S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==3.5.1 delta-spark==3.2.0 -q"
      ],
      "metadata": {
        "id": "He-KhOAogXfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed5484f2-1d42-4e74-a3f8-c8ec50ffe5f9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from delta import *\n",
        "\n",
        "builder = (\n",
        "  SparkSession.builder.appName(\"EtlAcidentesRecife\")\n",
        "  .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
        "  .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
        ")\n",
        "\n",
        "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
        "\n",
        "print(\"SparkSession and Delta Lake configured successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrV8TGwvhCBJ",
        "outputId": "1a95e85f-f927-4226-a415-04962b0761ce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SparkSession and Delta Lake configured successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Camada Bronze: Ingestão e Armazenamento dos Dados Brutos\n",
        "\n",
        "O objetivo da Camada Bronze é criar uma cópia fiel, histórica e imutável dos dados de origem. Nesta etapa, lemos todos os arquivos CSV, lidamos com as inconsistências de schema e salvamos os dados em uma única tabela Delta particionada."
      ],
      "metadata": {
        "id": "6r1Ge_RYjEuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. Análise de Consistência do Schema (Schema Drift Analysis)\n",
        "\n",
        "Antes de carregar todos os arquivos, é uma boa prática verificar se eles possuem a mesma estrutura. Nosso script de análise revelou um **Schema Drift** significativo: os nomes e o número de colunas mudam ao longo dos anos. Esta descoberta é crucial e justifica a necessidade de um schema unificado manual."
      ],
      "metadata": {
        "id": "oFRfPIM-jIok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_acidentes = spark.read \\\n",
        "  .option(\"header\", \"true\") \\\n",
        "  .option(\"inferSchema\", \"true\") \\\n",
        "  .option(\"delimiter\", \";\") \\\n",
        "  .csv('data/acidentes_2019.csv')"
      ],
      "metadata": {
        "id": "FoNzGbl1jKL3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_acidentes.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpX2ifrwj54a",
        "outputId": "7f229ba0-5205-41d8-932d-17715e13ca0d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- DATA: date (nullable = true)\n",
            " |-- hora: string (nullable = true)\n",
            " |-- natureza_acidente: string (nullable = true)\n",
            " |-- situacao: string (nullable = true)\n",
            " |-- bairro: string (nullable = true)\n",
            " |-- endereco: string (nullable = true)\n",
            " |-- numero: string (nullable = true)\n",
            " |-- detalhe_endereco_acidente: string (nullable = true)\n",
            " |-- complemento: string (nullable = true)\n",
            " |-- endereco_cruzamento: string (nullable = true)\n",
            " |-- numero_cruzamento: string (nullable = true)\n",
            " |-- referencia_cruzamento: string (nullable = true)\n",
            " |-- bairro_cruzamento: string (nullable = true)\n",
            " |-- num_semaforo: integer (nullable = true)\n",
            " |-- sentido_via: string (nullable = true)\n",
            " |-- tipo: string (nullable = true)\n",
            " |-- descricao: string (nullable = true)\n",
            " |-- auto: integer (nullable = true)\n",
            " |-- moto: integer (nullable = true)\n",
            " |-- ciclom: integer (nullable = true)\n",
            " |-- ciclista: integer (nullable = true)\n",
            " |-- pedestre: integer (nullable = true)\n",
            " |-- onibus: integer (nullable = true)\n",
            " |-- caminhao: integer (nullable = true)\n",
            " |-- viatura: integer (nullable = true)\n",
            " |-- outros: integer (nullable = true)\n",
            " |-- vitimas: integer (nullable = true)\n",
            " |-- vitimasfatais: integer (nullable = true)\n",
            " |-- acidente_verificado: string (nullable = true)\n",
            " |-- tempo_clima: string (nullable = true)\n",
            " |-- situacao_semaforo: string (nullable = true)\n",
            " |-- sinalizacao: string (nullable = true)\n",
            " |-- condicao_via: string (nullable = true)\n",
            " |-- conservacao_via: string (nullable = true)\n",
            " |-- ponto_controle: string (nullable = true)\n",
            " |-- situacao_placa: string (nullable = true)\n",
            " |-- velocidade_max_via: string (nullable = true)\n",
            " |-- mao_direcao: string (nullable = true)\n",
            " |-- divisao_via1: string (nullable = true)\n",
            " |-- divisao_via2: string (nullable = true)\n",
            " |-- divisao_via3: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_acidentes.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVXYPaJckD_6",
        "outputId": "332da6ff-63e2-4996-aa13-27f2ed08211b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+-----------------+----------+-----------+-------------------------------+------+---------------------------+-----------------------------------------------------------+-------------------------------+-----------------+-----------------------------------------------------------+-----------------+------------+-----------+------------------------+-----------------------------------------------------------------------------------+----+----+------+--------+--------+------+--------+-------+------+-------+-------------+-------------------+-----------+-----------------+---------------+------------+---------------+-----------------+--------------+------------------+-----------+----------------+------------+------------+\n",
            "|DATA      |hora    |natureza_acidente|situacao  |bairro     |endereco                       |numero|detalhe_endereco_acidente  |complemento                                                |endereco_cruzamento            |numero_cruzamento|referencia_cruzamento                                      |bairro_cruzamento|num_semaforo|sentido_via|tipo                    |descricao                                                                          |auto|moto|ciclom|ciclista|pedestre|onibus|caminhao|viatura|outros|vitimas|vitimasfatais|acidente_verificado|tempo_clima|situacao_semaforo|sinalizacao    |condicao_via|conservacao_via|ponto_controle   |situacao_placa|velocidade_max_via|mao_direcao|divisao_via1    |divisao_via2|divisao_via3|\n",
            "+----------+--------+-----------------+----------+-----------+-------------------------------+------+---------------------------+-----------------------------------------------------------+-------------------------------+-----------------+-----------------------------------------------------------+-----------------+------------+-----------+------------------------+-----------------------------------------------------------------------------------+----+----+------+--------+--------+------+--------+-------+------+-------+-------------+-------------------+-----------+-----------------+---------------+------------+---------------+-----------------+--------------+------------------+-----------+----------------+------------+------------+\n",
            "|2019-01-01|00:41:00|SEM VÍTIMA       |FINALIZADA|IPSEP      |AV RECIFE                      |NULL  |NULL                       |LADO OPOSTO AO Nº 3257                                     |AV RECIFE                      |NULL             |LADO OPOSTO AO Nº 3257                                     |IPSEP            |NULL        |SUBURBIO   |COLISÃO TRASEIRA        |ART.181, OBSTRUÇÃO DE ENTRADA E SAÍDA DE GARAGEM DO CONDOMINIO                     |2   |NULL|NULL  |NULL    |NULL    |NULL  |NULL    |NULL   |NULL  |0      |NULL         |Longo da via       |Bom        |Não existe       |Perfeito estado|Seca        |Perfeito estado|Não existe       |Não há placas |60 km/h           |Única      |Faixa seccionada|NULL        |NULL        |\n",
            "|2019-01-01|01:37:00|SEM VÍTIMA       |FINALIZADA|BOA VIAGEM |RUA PADRE BERNADINO PESSOA     |NULL  |RUA MINISTRO NELSON HUNGRIA|NULL                                                       |RUA PADRE BERNADINO PESSOA     |NULL             |NULL                                                       |BOA VIAGEM       |NULL        |NULL       |ABALROAMENTO TRANSVERSAL|COLISÃO ENTRE DOIS AUTOS S/V                                                       |2   |NULL|NULL  |NULL    |NULL    |NULL  |NULL    |NULL   |NULL  |0      |NULL         |Cruzamento         |Bom        |Não existe       |Perfeito estado|Seca        |Perfeito estado|Faixa de pedestre|Não há placas |NULL              |Única      |Não existe      |NULL        |NULL        |\n",
            "|2019-01-01|14:20:00|SEM VÍTIMA       |CANCELADA |BOA VIAGEM |AV ENGENHEIRO DOMINGOS FERREIRA|NULL  |RUA DOM JOSE LOPES         |EM FRENTE A DELEGACIA DE BOA VIAGEM, LADO ESQUERDO DA PISTA|AV ENGENHEIRO DOMINGOS FERREIRA|NULL             |EM FRENTE A DELEGACIA DE BOA VIAGEM, LADO ESQUERDO DA PISTA|BOA VIAGEM       |NULL        |NULL       |COLISÃO                 |COLISÃO ENTRE DOIS AUTOS S/V                                                       |2   |NULL|NULL  |NULL    |NULL    |NULL  |NULL    |NULL   |NULL  |0      |NULL         |NULL               |NULL       |NULL             |NULL           |NULL        |NULL           |NULL             |NULL          |NULL              |NULL       |NULL            |NULL        |NULL        |\n",
            "|2019-01-01|02:53:00|SEM VÍTIMA       |CANCELADA |IMBIRIBEIRA|AV GENERAL MAC ARTHUR          |100   |RUA JACY                   |EM FRENTE A ART LED ILUMINAÇÃO                             |AV GENERAL MAC ARTHUR          |100              |EM FRENTE A ART LED ILUMINAÇÃO                             |IMBIRIBEIRA      |NULL        |NULL       |COLISÃO                 |COLISÃO ENTRE DOIS AUTOS S/V                                                       |2   |NULL|NULL  |NULL    |NULL    |NULL  |NULL    |NULL   |NULL  |0      |NULL         |NULL               |NULL       |NULL             |NULL           |NULL        |NULL           |NULL             |NULL          |NULL              |NULL       |NULL            |NULL        |NULL        |\n",
            "|2019-01-01|08:17:00|COM VÍTIMA       |FINALIZADA|JAQUEIRA   |RUA TITO ROSAS                 |63    |NULL                       |ED. JARDINS DA JAQUEIRA                                    |RUA TITO ROSAS                 |63               |ED. JARDINS DA JAQUEIRA                                    |JAQUEIRA         |NULL        |SUBURBIO   |COLISÃO COM CICLISTA    |COLISÃO ENVOLVENDO ÔNIBUS E BICICLETA COM VÍTIMA. EQUIPE DEPAROU-SE COM O ACIDENTE.|NULL|NULL|NULL  |1       |NULL    |1     |NULL    |NULL   |NULL  |1      |NULL         |Longo da via       |Bom        |Não existe       |Perfeito estado|Seca        |Perfeito estado|Não existe       |Não há placas |40 km/h           |Única      |Faixa seccionada|NULL        |NULL        |\n",
            "+----------+--------+-----------------+----------+-----------+-------------------------------+------+---------------------------+-----------------------------------------------------------+-------------------------------+-----------------+-----------------------------------------------------------+-----------------+------------+-----------+------------------------+-----------------------------------------------------------------------------------+----+----+------+--------+--------+------+--------+-------+------+-------+-------------+-------------------+-----------+-----------------+---------------+------------+---------------+-----------------+--------------+------------------+-----------+----------------+------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_acidentes.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b2K_6GVBQSo",
        "outputId": "da184a76-dec9-4e39-cd25-9a50d25a0e8c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+-----------------+---------+---------+-------------------+------------------+-------------------------+--------------------+-------------------+------------------+---------------------+-----------------+------------------+-----------------+--------------------+------------------+------------------+------------------+------+-------------------+-------------------+-------------------+-------------------+------------------+-------------------+-------------------+-------------+-------------------+-----------+-----------------+---------------+------------+---------------+--------------+--------------+------------------+-----------+------------+------------+------------+\n",
            "|summary|    hora|natureza_acidente| situacao|   bairro|           endereco|            numero|detalhe_endereco_acidente|         complemento|endereco_cruzamento| numero_cruzamento|referencia_cruzamento|bairro_cruzamento|      num_semaforo|      sentido_via|                tipo|         descricao|              auto|              moto|ciclom|           ciclista|           pedestre|             onibus|           caminhao|           viatura|             outros|            vitimas|vitimasfatais|acidente_verificado|tempo_clima|situacao_semaforo|    sinalizacao|condicao_via|conservacao_via|ponto_controle|situacao_placa|velocidade_max_via|mao_direcao|divisao_via1|divisao_via2|divisao_via3|\n",
            "+-------+--------+-----------------+---------+---------+-------------------+------------------+-------------------------+--------------------+-------------------+------------------+---------------------+-----------------+------------------+-----------------+--------------------+------------------+------------------+------------------+------+-------------------+-------------------+-------------------+-------------------+------------------+-------------------+-------------------+-------------+-------------------+-----------+-----------------+---------------+------------+---------------+--------------+--------------+------------------+-----------+------------+------------+------------+\n",
            "|  count|   12046|            12058|    12058|    11914|              12009|              6013|                     4308|                9609|              12002|              6011|                 9606|            11909|              3029|             8293|               12062|             11762|             11140|              2904|    48|                224|                255|               1811|               1224|               122|                210|              12035|           25|               9191|       9706|             9581|           9524|        9673|           9525|          8670|          8733|              2858|       9522|        9130|         908|         150|\n",
            "|   mean|    NULL|             NULL|     NULL|     NULL|               NULL| 1184.249320652174|                     NULL|             2334.75|               NULL|1183.8995922528034|              2334.75|     9.98434034E8|289.15450643776825|           135.25|                NULL|              NULL|1.5841113105924596|1.0561294765840221|   1.0| 1.0089285714285714| 1.0509803921568628| 1.0209828823854223| 1.0212418300653594|1.0245901639344261|  1.061904761904762|0.21545492314083922|          1.0|               NULL|       NULL|             NULL|           NULL|        NULL|           NULL|          NULL|          NULL|              NULL|       NULL|        NULL|        NULL|        NULL|\n",
            "| stddev|    NULL|             NULL|     NULL|     NULL|               NULL|1527.5017701756722|                     NULL|   2635.866761301362|               NULL|1527.1183559269984|    2635.866761301362|             NULL| 217.6663272461742|76.97781065562552|                NULL|              NULL|0.6177047673742271|0.2433057550274722|   0.0|0.09427901670929757|0.23758342837999133|0.14336649028121842|0.15517171249419665| 0.155511140899212|0.24155831906253245|  0.490081563481564|          0.0|               NULL|       NULL|             NULL|           NULL|        NULL|           NULL|          NULL|          NULL|              NULL|       NULL|        NULL|        NULL|        NULL|\n",
            "|    min|00:00:00|            APOIO|CANCELADA|  AFLITOS|1 TRV JUSTICA E PAZ|            0940 A|      1 TRV JUSTICA E PAZ|10 METROS ANTES C...|1 TRV JUSTICA E PAZ|            0940 A| 10 METROS ANTES C...|        998434034|                 1|              191|ABALROAMENTO LONG...|   ,MOTO X CLASSIC|                 0|                 0|     1|                  1|                  1|                  1|                  0|                 1|                  1|                  0|            1|         Cruzamento|        Bom|      Com defeito|       Ilegível|     Molhada| Mal conservada|        Agente|         A-33a|           10 km/h|      Dupla|      Blocos|      Blocos|      Blocos|\n",
            "|    max|48:00:00|     VÍTIMA FATAL| PENDENTE|ÁGUA FRIA|           av norte|                 \\|     VIADUTO TANCREDO ...|ÁREA INTERNA DO S...|           av norte|                 \\| ÁREA INTERNA DO S...|        ÁGUA FRIA|              4038|        ÁGUA FRIA|          TOMBAMENTO|ÕNIBUS X AUTO. S/V|                 6|                 4|     1|                  2|                  3|                  2|                  2|                 2|                  2|                  7|            1|            Viaduto|    Nublado|      Sem defeito|Perfeito estado|        Seca|Perfeito estado|        Outros|          R-6c|           60 km/h|      Única|      Outros|      Outros|      Outros|\n",
            "+-------+--------+-----------------+---------+---------+-------------------+------------------+-------------------------+--------------------+-------------------+------------------+---------------------+-----------------+------------------+-----------------+--------------------+------------------+------------------+------------------+------+-------------------+-------------------+-------------------+-------------------+------------------+-------------------+-------------------+-------------+-------------------+-----------+-----------------+---------------+------------+---------------+--------------+--------------+------------------+-----------+------------+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "data_dir = 'data/'\n",
        "\n",
        "csv_files = sorted([f for f in os.listdir(data_dir) if f.endswith('.csv')])\n",
        "\n",
        "if not csv_files:\n",
        "  print(\"No CSV files found in the directory 'data/'\")\n",
        "else:\n",
        "  base_path = os.path.join(data_dir, csv_files[0])\n",
        "  base_header = spark.read.option(\"delimiter\", \";\").option(\"header\", \"true\").csv(base_path).columns\n",
        "\n",
        "  equals = True\n",
        "\n",
        "  for f in csv_files[1:]:\n",
        "    current_path = os.path.join(data_dir, f)\n",
        "    current_header = spark.read.option(\"delimiter\", \";\").option(\"header\", \"true\").csv(current_path).columns\n",
        "    if current_header != base_header:\n",
        "      equals = False\n",
        "      print(f\"\\n!!! ALERT: The header of '{f}' is DIFFERENT! Analysis:\")\n",
        "      base_set = set(base_header)\n",
        "      current_set = set(current_header)\n",
        "      removed_columns = base_set - current_set\n",
        "      if removed_columns:\n",
        "          print(f\"  - Missing columns in this file: {list(removed_columns)}\")\n",
        "      added_columns = current_set - base_set\n",
        "      if added_columns:\n",
        "          print(f\"  - Extra columns found in this file: {list(added_columns)}\")\n",
        "      if len(base_header) != len(current_header):\n",
        "            print(f\"  - Column count diverges: {len(base_header)} in reference vs. {len(current_header)} in this file.\") # Translated\n",
        "      print(\"-\" * 30)\n",
        "\n",
        "  if equals:\n",
        "      print(\"\\nGreat news! All CSV files have the same header.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxP8ymJ9uSDe",
        "outputId": "e56310ba-8523-496e-f0e1-b9aec45e580b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "!!! ALERT: The header of 'acidentes_2020.csv' is DIFFERENT! Analysis:\n",
            "  - Missing columns in this file: ['numero_cruzamento', 'referencia_cruzamento', 'DATA', 'endereco_cruzamento']\n",
            "  - Extra columns found in this file: ['data']\n",
            "  - Column count diverges: 41 in reference vs. 38 in this file.\n",
            "------------------------------\n",
            "\n",
            "!!! ALERT: The header of 'acidentes_2021.csv' is DIFFERENT! Analysis:\n",
            "  - Missing columns in this file: ['numero_cruzamento', 'referencia_cruzamento', 'descricao', 'DATA', 'endereco_cruzamento']\n",
            "  - Extra columns found in this file: ['data']\n",
            "  - Column count diverges: 41 in reference vs. 37 in this file.\n",
            "------------------------------\n",
            "\n",
            "!!! ALERT: The header of 'acidentes_2022.csv' is DIFFERENT! Analysis:\n",
            "  - Missing columns in this file: ['natureza_acidente', 'numero_cruzamento', 'referencia_cruzamento', 'descricao', 'DATA', 'endereco_cruzamento']\n",
            "  - Extra columns found in this file: ['natureza', 'data', 'Protocolo']\n",
            "  - Column count diverges: 41 in reference vs. 38 in this file.\n",
            "------------------------------\n",
            "\n",
            "!!! ALERT: The header of 'acidentes_2023.csv' is DIFFERENT! Analysis:\n",
            "  - Missing columns in this file: ['natureza_acidente', 'numero_cruzamento', 'referencia_cruzamento', 'descricao', 'DATA', 'endereco_cruzamento']\n",
            "  - Extra columns found in this file: ['natureza', 'data', 'Protocolo']\n",
            "  - Column count diverges: 41 in reference vs. 38 in this file.\n",
            "------------------------------\n",
            "\n",
            "!!! ALERT: The header of 'acidentes_2024.csv' is DIFFERENT! Analysis:\n",
            "  - Missing columns in this file: ['natureza_acidente', 'numero_cruzamento', 'referencia_cruzamento', 'descricao', 'DATA', 'endereco_cruzamento']\n",
            "  - Extra columns found in this file: ['natureza', 'data', 'Protocolo']\n",
            "  - Column count diverges: 41 in reference vs. 38 in this file.\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_acidentes2024 = spark.read \\\n",
        "  .option(\"header\", \"true\") \\\n",
        "  .option(\"inferSchema\", \"true\") \\\n",
        "  .option(\"delimiter\", \";\") \\\n",
        "  .csv('data/acidentes_2024.csv')\n",
        "\n",
        "df_acidentes2024.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaPigv8DF3QQ",
        "outputId": "ba9fd18d-a296-41a6-cab0-2df51575fc29"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+------------+----------+-------+--------------------+-----------------+-------------------------+--------------------+-----------------+------------+-----------+--------------------+----+----+------+--------+--------+------+--------+-------+------+-------+-------------+-------------------+-----------+-----------------+-----------+------------+---------------+--------------+--------------+------------------+-----------+------------+------------+------------+\n",
            "|summary|  Protocolo|    natureza|  situacao| bairro|            endereco|           numero|detalhe_endereco_acidente|         complemento|bairro_cruzamento|num_semaforo|sentido_via|                tipo|auto|moto|ciclom|ciclista|pedestre|onibus|caminhao|viatura|outros|vitimas|vitimasfatais|acidente_verificado|tempo_clima|situacao_semaforo|sinalizacao|condicao_via|conservacao_via|ponto_controle|situacao_placa|velocidade_max_via|mao_direcao|divisao_via1|divisao_via2|divisao_via3|\n",
            "+-------+-----------+------------+----------+-------+--------------------+-----------------+-------------------------+--------------------+-----------------+------------+-----------+--------------------+----+----+------+--------+--------+------+--------+-------+------+-------+-------------+-------------------+-----------+-----------------+-----------+------------+---------------+--------------+--------------+------------------+-----------+------------+------------+------------+\n",
            "|  count|       5315|        5315|      5315|   5308|                5297|             2419|                      698|                5036|             5308|         199|        377|                5285|5315|5315|  5315|    5315|    5315|  5315|    5315|   5315|  5315|   5315|         5315|                  0|          0|                0|          0|           0|              0|             0|             0|                 0|          0|           0|           0|           0|\n",
            "|   mean|       NULL|        NULL|      NULL|   NULL|                NULL|1425.840475180314|                     NULL|                NULL|             NULL|        NULL|     1987.0|                NULL|NULL|NULL|  NULL|    NULL|    NULL|  NULL|    NULL|   NULL|  NULL|   NULL|         NULL|               NULL|       NULL|             NULL|       NULL|        NULL|           NULL|          NULL|          NULL|              NULL|       NULL|        NULL|        NULL|        NULL|\n",
            "| stddev|       NULL|        NULL|      NULL|   NULL|                NULL|2193.806380777639|                     NULL|                NULL|             NULL|        NULL|       NULL|                NULL|NULL|NULL|  NULL|    NULL|    NULL|  NULL|    NULL|   NULL|  NULL|   NULL|         NULL|               NULL|       NULL|             NULL|       NULL|        NULL|           NULL|          NULL|          NULL|              NULL|       NULL|        NULL|        NULL|        NULL|\n",
            "|    min|202406373,0|  COM VÍTIMA| CANCELADA|AFLITOS|1 TRV DOUTOR SABI...|                1|     1 TRV DOUTOR SABI...|( JORDÃO BAIXO ),...|          AFLITOS|       100,0|       1987|ATROPELAMENTO DE ...| 0,0| 0,0|   0,0|     0,0|     0,0|   0,0|     0,0|    0,0|   0,0|    0,0|          0,0|               NULL|       NULL|             NULL|       NULL|        NULL|           NULL|          NULL|          NULL|              NULL|       NULL|        NULL|        NULL|        NULL|\n",
            "|    max|   299315,0|VÍTIMA FATAL|FINALIZADA|  ZUMBI|VIADUTO ULYSSES G...|               SN|     VDO PAPA JOAO PAU...|sobre a ponte Jos...|            ZUMBI|        96,0|   SUBURBIO|          TOMBAMENTO| 4,0| 3,0|   1,0|     2,0|     2,0|   2,0|     2,0|    2,0|  24,0|    4,0|          6,0|               NULL|       NULL|             NULL|       NULL|        NULL|           NULL|          NULL|          NULL|              NULL|       NULL|        NULL|        NULL|        NULL|\n",
            "+-------+-----------+------------+----------+-------+--------------------+-----------------+-------------------------+--------------------+-----------------+------------+-----------+--------------------+----+----+------+--------+--------+------+--------+-------+------+-------+-------------+-------------------+-----------+-----------------+-----------+------------+---------------+--------------+--------------+------------------+-----------+------------+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Definição do Schema Unificado (Unified Schema Definition)\n",
        "\n",
        "Com base na análise, definimos um **schema unificado e explícito** usando `StructType`. Este schema representa o \"superconjunto\" de todas as colunas encontradas em todos os arquivos, padronizando os nomes (ex: `DATA` para `data`) e definindo os tipos de dados corretos. Manter todas as colunas como `nullable=True` nesta etapa garante que a ingestão não falhe por dados faltantes na origem."
      ],
      "metadata": {
        "id": "9BBIyqqktrns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, DateType, IntegerType\n",
        "\n",
        "unified_schema = StructType([\n",
        "  StructField('data', DateType(), True),\n",
        "  StructField('hora', StringType(), True),\n",
        "  StructField('natureza_acidente', StringType(), True),\n",
        "  StructField('situacao', StringType(), True),\n",
        "  StructField('protocolo', StringType(), True),\n",
        "\n",
        "  StructField('bairro', StringType(), True),\n",
        "  StructField('endereco', StringType(), True),\n",
        "  StructField('numero', StringType(), True),\n",
        "\n",
        "  StructField('detalhe_endereco_acidente', StringType(), True),\n",
        "  StructField('complemento', StringType(), True),\n",
        "  StructField('endereco_cruzamento', StringType(), True),\n",
        "  StructField('numero_cruzamento', StringType(), True),\n",
        "  StructField('referencia_cruzamento', StringType(), True),\n",
        "  StructField('bairro_cruzamento', StringType(), True),\n",
        "  StructField('num_semaforo', IntegerType(), True),\n",
        "  StructField('sentido_via', StringType(), True),\n",
        "  StructField('tipo', StringType(), True),\n",
        "  StructField('descricao', StringType(), True),\n",
        "\n",
        "  StructField('auto', IntegerType(), True),\n",
        "  StructField('moto', IntegerType(), True),\n",
        "  StructField('ciclom', IntegerType(), True),\n",
        "  StructField('ciclista', IntegerType(), True),\n",
        "  StructField('pedestre', IntegerType(), True),\n",
        "  StructField('onibus', IntegerType(), True),\n",
        "  StructField('caminhao', IntegerType(), True),\n",
        "  StructField('viatura', IntegerType(), True),\n",
        "  StructField('outros', IntegerType(), True),\n",
        "  StructField('vitimas', IntegerType(), True),\n",
        "  StructField('vitimas_fatais', IntegerType(), True),\n",
        "\n",
        "  StructField('acidente_verificado', StringType(), True),\n",
        "  StructField('tempo_clima', StringType(), True),\n",
        "  StructField('situacao_semaforo', StringType(), True),\n",
        "  StructField('sinalizacao', StringType(), True),\n",
        "  StructField('condicao_via', StringType(), True),\n",
        "  StructField('conservacao_via', StringType(), True),\n",
        "  StructField('ponto_controle', StringType(), True),\n",
        "  StructField('situacao_placa', StringType(), True),\n",
        "  StructField('velocidade_max_via', IntegerType(), True),\n",
        "  StructField('mao_direcao', StringType(), True),\n",
        "\n",
        "  StructField('divisao_via1', StringType(), True),\n",
        "  StructField('divisao_via2', StringType(), True),\n",
        "  StructField('divisao_via3', StringType(), True)\n",
        "\n",
        "])\n",
        "\n",
        "schema_columns = unified_schema.names\n",
        "print(f\"Your Schema have {len(schema_columns)} columns.\")\n",
        "print(unified_schema)"
      ],
      "metadata": {
        "id": "pukidjastueN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00016828-77eb-4af0-baf2-559ffda2b0b9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your Schema have 42 columns.\n",
            "StructType([StructField('data', DateType(), True), StructField('hora', StringType(), True), StructField('natureza_acidente', StringType(), True), StructField('situacao', StringType(), True), StructField('protocolo', StringType(), True), StructField('bairro', StringType(), True), StructField('endereco', StringType(), True), StructField('numero', StringType(), True), StructField('detalhe_endereco_acidente', StringType(), True), StructField('complemento', StringType(), True), StructField('endereco_cruzamento', StringType(), True), StructField('numero_cruzamento', StringType(), True), StructField('referencia_cruzamento', StringType(), True), StructField('bairro_cruzamento', StringType(), True), StructField('num_semaforo', IntegerType(), True), StructField('sentido_via', StringType(), True), StructField('tipo', StringType(), True), StructField('descricao', StringType(), True), StructField('auto', IntegerType(), True), StructField('moto', IntegerType(), True), StructField('ciclom', IntegerType(), True), StructField('ciclista', IntegerType(), True), StructField('pedestre', IntegerType(), True), StructField('onibus', IntegerType(), True), StructField('caminhao', IntegerType(), True), StructField('viatura', IntegerType(), True), StructField('outros', IntegerType(), True), StructField('vitimas', IntegerType(), True), StructField('vitimas_fatais', IntegerType(), True), StructField('acidente_verificado', StringType(), True), StructField('tempo_clima', StringType(), True), StructField('situacao_semaforo', StringType(), True), StructField('sinalizacao', StringType(), True), StructField('condicao_via', StringType(), True), StructField('conservacao_via', StringType(), True), StructField('ponto_controle', StringType(), True), StructField('situacao_placa', StringType(), True), StructField('velocidade_max_via', IntegerType(), True), StructField('mao_direcao', StringType(), True), StructField('divisao_via1', StringType(), True), StructField('divisao_via2', StringType(), True), StructField('divisao_via3', StringType(), True)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_dir = 'data'\n",
        "all_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.csv')])\n",
        "\n",
        "all_headers = set()\n",
        "\n",
        "for file_path in all_files:\n",
        "  header = spark.read.option(\"delimiter\", \";\").option(\"header\", \"true\").csv(file_path).columns\n",
        "  all_headers.update(header)\n",
        "\n",
        "unique_column_list = sorted(list(all_headers))\n",
        "\n",
        "print(f\"Found {len(unique_column_list)} unique columns across all files:\")\n",
        "print(unique_column_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCAqyZft6bW8",
        "outputId": "c08264bf-68ee-407b-9e71-beb6c9cd504b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 44 unique columns across all files:\n",
            "['DATA', 'Protocolo', 'acidente_verificado', 'auto', 'bairro', 'bairro_cruzamento', 'caminhao', 'ciclista', 'ciclom', 'complemento', 'condicao_via', 'conservacao_via', 'data', 'descricao', 'detalhe_endereco_acidente', 'divisao_via1', 'divisao_via2', 'divisao_via3', 'endereco', 'endereco_cruzamento', 'hora', 'mao_direcao', 'moto', 'natureza', 'natureza_acidente', 'num_semaforo', 'numero', 'numero_cruzamento', 'onibus', 'outros', 'pedestre', 'ponto_controle', 'referencia_cruzamento', 'sentido_via', 'sinalizacao', 'situacao', 'situacao_placa', 'situacao_semaforo', 'tempo_clima', 'tipo', 'velocidade_max_via', 'viatura', 'vitimas', 'vitimasfatais']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_columns_standardized = [header.lower() for header in unique_column_list]\n",
        "print(f\"The source files have {len(source_columns_standardized)} unique standardized columns.\")\n",
        "\n",
        "extra_columns = set(schema_columns) - set(source_columns_standardized)\n",
        "if extra_columns:\n",
        "  print(f\"The extra columns are: {extra_columns}\")\n",
        "else:\n",
        "  print(\"No extra columns found.\")\n",
        "\n",
        "over_columns = set(source_columns_standardized) - set(schema_columns)\n",
        "if over_columns:\n",
        "  print(f\"The missing columns are: {over_columns}\")\n",
        "else:\n",
        "  print(\"No missing columns found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95F7s0XIHjqY",
        "outputId": "bb5eb245-8d23-4a40-86f4-9124b00e1aaa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source files have 44 unique standardized columns.\n",
            "The extra columns are: {'vitimas_fatais'}\n",
            "The missing columns are: {'natureza', 'vitimasfatais'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3. Carga, Mapeamento e Enriquecimento (Ingestion, Mapping & Enrichment)\n",
        "\n",
        "Implementamos um loop para processar cada arquivo CSV. Para lidar com o Schema Drift, utilizamos o padrão **\"Read, Rename, and UnionByName\"**:\n",
        "1.  **Read:** Lemos cada arquivo individualmente, deixando o Spark inferir os nomes originais do cabeçalho.\n",
        "2.  **Rename:** Renomeamos as colunas inconsistentes para se alinharem ao nosso schema padrão.\n",
        "3.  **UnionByName:** Unimos o DataFrame tratado ao DataFrame final, alinhando as colunas pelo nome.\n",
        "\n",
        "Além disso, enriquecemos os dados com duas colunas de metadados essenciais:\n",
        "- `source_file`: Para rastreabilidade da origem de cada registro.\n",
        "- `year`: Para permitir o particionamento da tabela."
      ],
      "metadata": {
        "id": "RCx_RwdeLJlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bronze_final = spark.createDataFrame([], unified_schema)"
      ],
      "metadata": {
        "id": "rR8_6wRqnbUF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'data'\n",
        "all_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.csv')])\n",
        "\n",
        "for file_path in all_files:\n",
        "    df_raw = spark.read.option(\"header\", \"true\").option(\"delimiter\", \";\").option('inferSchema', True).csv(file_path)\n",
        "\n",
        "    df_renamed = df_raw.withColumnRenamed('DATA','data') \\\n",
        "                       .withColumnRenamed('natureza', 'natureza_acidente') \\\n",
        "                       .withColumnRenamed('vitimasfatais', 'vitimas_fatais') \\\n",
        "                       .withColumnRenamed('Protocolo', 'protocolo')\n",
        "\n",
        "    df_bronze_final = df_bronze_final.unionByName(df_renamed, allowMissingColumns=True)"
      ],
      "metadata": {
        "id": "7pe0_W81L98C"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df_columns = df_bronze_final.columns\n",
        "\n",
        "expected_schema_columns = unified_schema.names\n",
        "\n",
        "missing_columns = set(expected_schema_columns) - set(final_df_columns)\n",
        "extra_columns = set(final_df_columns) - set(expected_schema_columns)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"Final Schema Validation Report\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "if not missing_columns and not extra_columns:\n",
        "    print(f\"✅ SUCCESS! The final DataFrame schema perfectly matches the expected unified schema.\")\n",
        "    print(f\"Total columns loaded: {len(final_df_columns)}\")\n",
        "else:\n",
        "    print(\"⚠️ ATTENTION: Discrepancy found!\")\n",
        "    if missing_columns:\n",
        "        print(f\"  - Columns defined in schema but MISSING from final DataFrame: {list(missing_columns)}\")\n",
        "    if extra_columns:\n",
        "        print(f\"  - EXTRA columns found in final DataFrame that were not in schema: {list(extra_columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDoZTpido5oT",
        "outputId": "6a35e71c-c3fb-44c0-ebd8-28d6fd0644de"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "Final Schema Validation Report\n",
            "==================================================\n",
            "✅ SUCCESS! The final DataFrame schema perfectly matches the expected unified schema.\n",
            "Total columns loaded: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import input_file_name, year, col\n",
        "\n",
        "\n",
        "df_bronze_with_metadata = df_bronze_final \\\n",
        "  .withColumn('source_file', input_file_name()) \\\n",
        "  .withColumn('year', year(col('data')))\n",
        "\n",
        "print(\"DataFrame with source_file metadata column:\")\n",
        "df_bronze_with_metadata.select(\"data\", \"bairro\", \"source_file\", \"year\").show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MVHFf6BuFlx",
        "outputId": "7e2a2842-6893-492c-80a3-1de7202e7f45"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with source_file metadata column:\n",
            "+----------+-----------+---------------------------------------+----+\n",
            "|data      |bairro     |source_file                            |year|\n",
            "+----------+-----------+---------------------------------------+----+\n",
            "|2019-01-01|IPSEP      |file:///content/data/acidentes_2019.csv|2019|\n",
            "|2019-01-01|BOA VIAGEM |file:///content/data/acidentes_2019.csv|2019|\n",
            "|2019-01-01|BOA VIAGEM |file:///content/data/acidentes_2019.csv|2019|\n",
            "|2019-01-01|IMBIRIBEIRA|file:///content/data/acidentes_2019.csv|2019|\n",
            "|2019-01-01|JAQUEIRA   |file:///content/data/acidentes_2019.csv|2019|\n",
            "+----------+-----------+---------------------------------------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4. Salvando a Tabela Bronze (Saving the Bronze Table)\n",
        "\n",
        "Finalmente, salvamos o DataFrame unificado e enriquecido como uma tabela Delta, que é a base do nosso Lakehouse. A tabela é salva no modo `overwrite` e **particionada por ano** (`partitionBy(\"year\")`) para otimizar drasticamente a performance de futuras consultas que filtrem por data.*texto em itálico*"
      ],
      "metadata": {
        "id": "wwPnej8P7ZeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bronze_table_path = \"delta_lake/bronze/acidentes\"\n",
        "\n",
        "print(\"Saving Bronze table...\")\n",
        "\n",
        "df_bronze_with_metadata.write \\\n",
        "    .format(\"delta\") \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .partitionBy(\"year\") \\\n",
        "    .save(bronze_table_path)\n",
        "\n",
        "print(f\"SUCCESS: Bronze table saved successfully to '{bronze_table_path}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asGlciWX245_",
        "outputId": "2941a3cc-f9b3-41c6-855e-fdd82e71f187"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Bronze table...\n",
            "SUCCESS: Bronze table saved successfully to 'delta_lake/bronze/acidentes'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusão da Camada Bronze\n",
        "\n",
        "A Camada Bronze está completa! Nossos dados brutos de múltiplos arquivos inconsistentes estão agora armazenados em uma única tabela Delta, com schema unificado, metadados de linhagem e otimizada para leitura com particionamento.\n",
        "\n",
        "**Próximo Passo:** Iniciar a **Camada Silver**, onde vamos limpar, validar e enriquecer estes dados."
      ],
      "metadata": {
        "id": "8TE3egVP7hwN"
      }
    }
  ]
}